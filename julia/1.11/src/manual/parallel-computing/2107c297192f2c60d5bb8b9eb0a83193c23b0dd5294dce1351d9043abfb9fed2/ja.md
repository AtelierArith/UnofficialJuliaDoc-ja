# Parallel Computing

Juliaは、次の4つの並行および並列プログラミングのカテゴリをサポートしています：

1. **非同期の「タスク」、またはコルーチン**:

    Julia タスクは、I/O、イベント処理、プロデューサー-コンシューマー プロセス、および同様のパターンのために計算を一時停止および再開することを可能にします。 タスクは、[`wait`](@ref) や [`fetch`](@ref) のような操作を通じて同期することができ、[`Channel`](@ref) を介して通信します。 厳密には自体としては並列計算ではありませんが、Julia は [`Task`](@ref) を複数のスレッドでスケジュールすることを許可します。
2. **マルチスレッド**:

    ジュリアの [multi-threading](@ref man-multithreading) は、メモリを共有しながら、複数のスレッドまたはCPUコアでタスクを同時にスケジュールする能力を提供します。これは通常、自分のPCや単一の大規模マルチコアサーバーで並列処理を得る最も簡単な方法です。ジュリアのマルチスレッドは構成可能です。あるマルチスレッド関数が別のマルチスレッド関数を呼び出すと、ジュリアは利用可能なリソース上で全てのスレッドをグローバルにスケジュールし、オーバーサブスクリプションを避けます。
3. **分散コンピューティング**:

    分散コンピューティングは、別々のメモリ空間を持つ複数のJuliaプロセスを実行します。これらは同じコンピュータ上でも、複数のコンピュータ上でも実行できます。[`Distributed`](@ref man-distributed)標準ライブラリは、Julia関数のリモート実行の機能を提供します。この基本的なビルディングブロックを使用することで、さまざまな種類の分散コンピューティングの抽象化を構築することが可能です。[`DistributedArrays.jl`](https://github.com/JuliaParallel/DistributedArrays.jl)のようなパッケージは、そのような抽象化の一例です。一方、[`MPI.jl`](https://github.com/JuliaParallel/MPI.jl)や[`Elemental.jl`](https://github.com/JuliaParallel/Elemental.jl)のようなパッケージは、既存のMPIエコシステムのライブラリへのアクセスを提供します。
4. **GPUコンピューティング**:

    Julia GPUコンパイラは、GPU上でJuliaコードをネイティブに実行する機能を提供します。GPUをターゲットとしたJuliaパッケージの豊富なエコシステムがあります。[JuliaGPU.org](https://juliagpu.org)ウェブサイトでは、機能、サポートされているGPU、関連パッケージおよびドキュメントのリストが提供されています。
