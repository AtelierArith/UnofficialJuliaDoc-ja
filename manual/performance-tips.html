<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Performance Tips · The Julia Language</title><meta name="title" content="Performance Tips · The Julia Language"/><meta property="og:title" content="Performance Tips · The Julia Language"/><meta property="twitter:title" content="Performance Tips · The Julia Language"/><meta name="description" content="Documentation for The Julia Language."/><meta property="og:description" content="Documentation for The Julia Language."/><meta property="twitter:description" content="Documentation for The Julia Language."/><script async src="https://www.googletagmanager.com/gtag/js?id=UA-28835595-6"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-28835595-6', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/julia-manual.css" rel="stylesheet" type="text/css"/><link href="../assets/julia.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../index.html"><img class="docs-light-only" src="../assets/logo.svg" alt="The Julia Language logo"/><img class="docs-dark-only" src="../assets/logo-dark.svg" alt="The Julia Language logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../index.html">Julia Documentation</a></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox" checked/><label class="tocitem" for="menuitem-3"><span class="docs-label">Manual</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="getting-started.html">Getting Started</a></li><li><a class="tocitem" href="installation.html">Installation</a></li><li><a class="tocitem" href="variables.html">Variables</a></li><li><a class="tocitem" href="integers-and-floating-point-numbers.html">Integers and Floating-Point Numbers</a></li><li><a class="tocitem" href="mathematical-operations.html">Mathematical Operations and Elementary Functions</a></li><li><a class="tocitem" href="complex-and-rational-numbers.html">Complex and Rational Numbers</a></li><li><a class="tocitem" href="strings.html">Strings</a></li><li><a class="tocitem" href="functions.html">Functions</a></li><li><a class="tocitem" href="control-flow.html">Control Flow</a></li><li><a class="tocitem" href="variables-and-scoping.html">Scope of Variables</a></li><li><a class="tocitem" href="types.html">Types</a></li><li><a class="tocitem" href="methods.html">Methods</a></li><li><a class="tocitem" href="constructors.html">Constructors</a></li><li><a class="tocitem" href="conversion-and-promotion.html">Conversion and Promotion</a></li><li><a class="tocitem" href="interfaces.html">Interfaces</a></li><li><a class="tocitem" href="modules.html">Modules</a></li><li><a class="tocitem" href="documentation.html">Documentation</a></li><li><a class="tocitem" href="metaprogramming.html">Metaprogramming</a></li><li><a class="tocitem" href="arrays.html">Single- and multi-dimensional Arrays</a></li><li><a class="tocitem" href="missing.html">Missing Values</a></li><li><a class="tocitem" href="networking-and-streams.html">Networking and Streams</a></li><li><a class="tocitem" href="parallel-computing.html">Parallel Computing</a></li><li><a class="tocitem" href="asynchronous-programming.html">Asynchronous Programming</a></li><li><a class="tocitem" href="multi-threading.html">Multi-Threading</a></li><li><a class="tocitem" href="distributed-computing.html">Multi-processing and Distributed Computing</a></li><li><a class="tocitem" href="running-external-programs.html">Running External Programs</a></li><li><a class="tocitem" href="calling-c-and-fortran-code.html">Calling C and Fortran Code</a></li><li><a class="tocitem" href="handling-operating-system-variation.html">Handling Operating System Variation</a></li><li><a class="tocitem" href="environment-variables.html">Environment Variables</a></li><li><a class="tocitem" href="embedding.html">Embedding Julia</a></li><li><a class="tocitem" href="code-loading.html">Code Loading</a></li><li><a class="tocitem" href="profile.html">Profiling</a></li><li><a class="tocitem" href="stacktraces.html">Stack Traces</a></li><li class="is-active"><a class="tocitem" href="performance-tips.html">Performance Tips</a><ul class="internal"><li><a class="tocitem" href="#Performance-critical-code-should-be-inside-a-function"><span>Performance critical code should be inside a function</span></a></li><li><a class="tocitem" href="#Avoid-untyped-global-variables"><span>Avoid untyped global variables</span></a></li><li><a class="tocitem" href="#Measure-performance-with-[@time](@ref)-and-pay-attention-to-memory-allocation"><span>Measure performance with <code>@time</code> and pay attention to memory allocation</span></a></li><li><a class="tocitem" href="#tools"><span>Tools</span></a></li><li><a class="tocitem" href="#man-performance-abstract-container"><span>Avoid containers with abstract type parameters</span></a></li><li><a class="tocitem" href="#Type-declarations"><span>Type declarations</span></a></li><li><a class="tocitem" href="#Break-functions-into-multiple-definitions"><span>Break functions into multiple definitions</span></a></li><li><a class="tocitem" href="#Write-&quot;type-stable&quot;-functions"><span>Write &quot;type-stable&quot; functions</span></a></li><li><a class="tocitem" href="#Avoid-changing-the-type-of-a-variable"><span>Avoid changing the type of a variable</span></a></li><li><a class="tocitem" href="#kernel-functions"><span>Separate kernel functions (aka, function barriers)</span></a></li><li><a class="tocitem" href="#man-performance-value-type"><span>Types with values-as-parameters</span></a></li><li><a class="tocitem" href="#The-dangers-of-abusing-multiple-dispatch-(aka,-more-on-types-with-values-as-parameters)"><span>The dangers of abusing multiple dispatch (aka, more on types with values-as-parameters)</span></a></li><li><a class="tocitem" href="#man-performance-column-major"><span>Access arrays in memory order, along columns</span></a></li><li><a class="tocitem" href="#Pre-allocating-outputs"><span>Pre-allocating outputs</span></a></li><li><a class="tocitem" href="#man-perftips-mutablearithmetics"><span>Use <code>MutableArithmetics</code> for more control over allocation for mutable arithmetic types</span></a></li><li><a class="tocitem" href="#More-dots:-Fuse-vectorized-operations"><span>More dots: Fuse vectorized operations</span></a></li><li><a class="tocitem" href="#man-performance-unfuse"><span>Fewer dots: Unfuse certain intermediate broadcasts</span></a></li><li><a class="tocitem" href="#man-performance-views"><span>Consider using views for slices</span></a></li><li><a class="tocitem" href="#Copying-data-is-not-always-bad"><span>Copying data is not always bad</span></a></li><li><a class="tocitem" href="#Consider-StaticArrays.jl-for-small-fixed-size-vector/matrix-operations"><span>Consider StaticArrays.jl for small fixed-size vector/matrix operations</span></a></li><li><a class="tocitem" href="#Avoid-string-interpolation-for-I/O"><span>Avoid string interpolation for I/O</span></a></li><li><a class="tocitem" href="#Optimize-network-I/O-during-parallel-execution"><span>Optimize network I/O during parallel execution</span></a></li><li><a class="tocitem" href="#Fix-deprecation-warnings"><span>Fix deprecation warnings</span></a></li><li><a class="tocitem" href="#Tweaks"><span>Tweaks</span></a></li><li><a class="tocitem" href="#man-performance-annotations"><span>Performance Annotations</span></a></li><li><a class="tocitem" href="#Treat-Subnormal-Numbers-as-Zeros"><span>Treat Subnormal Numbers as Zeros</span></a></li><li><a class="tocitem" href="#man-code-warntype"><span><code>@code_warntype</code></span></a></li><li><a class="tocitem" href="#man-performance-captured"><span>Performance of captured variable</span></a></li><li><a class="tocitem" href="#man-multithreading-linear-algebra"><span>Multithreading and linear algebra</span></a></li><li><a class="tocitem" href="#man-backends-linear-algebra"><span>Alternative linear algebra backends</span></a></li><li><a class="tocitem" href="#Execution-latency,-package-loading-and-package-precompiling-time"><span>Execution latency, package loading and package precompiling time</span></a></li></ul></li><li><a class="tocitem" href="workflow-tips.html">Workflow Tips</a></li><li><a class="tocitem" href="style-guide.html">Style Guide</a></li><li><a class="tocitem" href="faq.html">Frequently Asked Questions</a></li><li><a class="tocitem" href="noteworthy-differences.html">Noteworthy Differences from other Languages</a></li><li><a class="tocitem" href="unicode-input.html">Unicode Input</a></li><li><a class="tocitem" href="command-line-interface.html">Command-line Interface</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">Base</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../base/base.html">Essentials</a></li><li><a class="tocitem" href="../base/collections.html">Collections and Data Structures</a></li><li><a class="tocitem" href="../base/math.html">Mathematics</a></li><li><a class="tocitem" href="../base/numbers.html">Numbers</a></li><li><a class="tocitem" href="../base/strings.html">Strings</a></li><li><a class="tocitem" href="../base/arrays.html">Arrays</a></li><li><a class="tocitem" href="../base/parallel.html">Tasks</a></li><li><a class="tocitem" href="../base/multi-threading.html">Multi-Threading</a></li><li><a class="tocitem" href="../base/scopedvalues.html">Scoped Values</a></li><li><a class="tocitem" href="../base/constants.html">Constants</a></li><li><a class="tocitem" href="../base/file.html">Filesystem</a></li><li><a class="tocitem" href="../base/io-network.html">I/O and Network</a></li><li><a class="tocitem" href="../base/punctuation.html">Punctuation</a></li><li><a class="tocitem" href="../base/sort.html">Sorting and Related Functions</a></li><li><a class="tocitem" href="../base/iterators.html">Iteration utilities</a></li><li><a class="tocitem" href="../base/reflection.html">Reflection and introspection</a></li><li><a class="tocitem" href="../base/c.html">C Interface</a></li><li><a class="tocitem" href="../base/libc.html">C Standard Library</a></li><li><a class="tocitem" href="../base/stacktraces.html">StackTraces</a></li><li><a class="tocitem" href="../base/simd-types.html">SIMD Support</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">Standard Library</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../stdlib/ArgTools.html">ArgTools</a></li><li><a class="tocitem" href="../stdlib/Artifacts.html">Artifacts</a></li><li><a class="tocitem" href="../stdlib/Base64.html">Base64</a></li><li><a class="tocitem" href="../stdlib/CRC32c.html">CRC32c</a></li><li><a class="tocitem" href="../stdlib/Dates.html">Dates</a></li><li><a class="tocitem" href="../stdlib/DelimitedFiles.html">Delimited Files</a></li><li><a class="tocitem" href="../stdlib/Distributed.html">Distributed Computing</a></li><li><a class="tocitem" href="../stdlib/Downloads.html">Downloads</a></li><li><a class="tocitem" href="../stdlib/FileWatching.html">File Events</a></li><li><a class="tocitem" href="../stdlib/Future.html">Future</a></li><li><a class="tocitem" href="../stdlib/InteractiveUtils.html">Interactive Utilities</a></li><li><a class="tocitem" href="../stdlib/LazyArtifacts.html">Lazy Artifacts</a></li><li><a class="tocitem" href="../stdlib/LibCURL.html">LibCURL</a></li><li><a class="tocitem" href="../stdlib/LibGit2.html">LibGit2</a></li><li><a class="tocitem" href="../stdlib/Libdl.html">Dynamic Linker</a></li><li><a class="tocitem" href="../stdlib/LinearAlgebra.html">Linear Algebra</a></li><li><a class="tocitem" href="../stdlib/Logging.html">Logging</a></li><li><a class="tocitem" href="../stdlib/Markdown.html">Markdown</a></li><li><a class="tocitem" href="../stdlib/Mmap.html">Memory-mapped I/O</a></li><li><a class="tocitem" href="../stdlib/NetworkOptions.html">Network Options</a></li><li><a class="tocitem" href="../stdlib/Pkg.html">Pkg</a></li><li><a class="tocitem" href="../stdlib/Printf.html">Printf</a></li><li><a class="tocitem" href="../stdlib/Profile.html">Profiling</a></li><li><a class="tocitem" href="../stdlib/REPL.html">The Julia REPL</a></li><li><a class="tocitem" href="../stdlib/Random.html">Random Numbers</a></li><li><a class="tocitem" href="../stdlib/SHA.html">SHA</a></li><li><a class="tocitem" href="../stdlib/Serialization.html">Serialization</a></li><li><a class="tocitem" href="../stdlib/SharedArrays.html">Shared Arrays</a></li><li><a class="tocitem" href="../stdlib/Sockets.html">Sockets</a></li><li><a class="tocitem" href="../stdlib/SparseArrays.html">Sparse Arrays</a></li><li><a class="tocitem" href="../stdlib/Statistics.html">Statistics</a></li><li><a class="tocitem" href="../stdlib/StyledStrings.html">StyledStrings</a></li><li><a class="tocitem" href="../stdlib/TOML.html">TOML</a></li><li><a class="tocitem" href="../stdlib/Tar.html">Tar</a></li><li><a class="tocitem" href="../stdlib/Test.html">Unit Testing</a></li><li><a class="tocitem" href="../stdlib/UUIDs.html">UUIDs</a></li><li><a class="tocitem" href="../stdlib/Unicode.html">Unicode</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">Developer Documentation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><input class="collapse-toggle" id="menuitem-6-1" type="checkbox"/><label class="tocitem" for="menuitem-6-1"><span class="docs-label">Documentation of Julia&#39;s Internals</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../devdocs/init.html">Initialization of the Julia runtime</a></li><li><a class="tocitem" href="../devdocs/ast.html">Julia ASTs</a></li><li><a class="tocitem" href="../devdocs/types.html">More about types</a></li><li><a class="tocitem" href="../devdocs/object.html">Memory layout of Julia Objects</a></li><li><a class="tocitem" href="../devdocs/eval.html">Eval of Julia code</a></li><li><a class="tocitem" href="../devdocs/callconv.html">Calling Conventions</a></li><li><a class="tocitem" href="../devdocs/compiler.html">High-level Overview of the Native-Code Generation Process</a></li><li><a class="tocitem" href="../devdocs/functions.html">Julia Functions</a></li><li><a class="tocitem" href="../devdocs/cartesian.html">Base.Cartesian</a></li><li><a class="tocitem" href="../devdocs/meta.html">Talking to the compiler (the <code>:meta</code> mechanism)</a></li><li><a class="tocitem" href="../devdocs/subarrays.html">SubArrays</a></li><li><a class="tocitem" href="../devdocs/isbitsunionarrays.html">isbits Union Optimizations</a></li><li><a class="tocitem" href="../devdocs/sysimg.html">System Image Building</a></li><li><a class="tocitem" href="../devdocs/pkgimg.html">Package Images</a></li><li><a class="tocitem" href="../devdocs/llvm-passes.html">Custom LLVM Passes</a></li><li><a class="tocitem" href="../devdocs/llvm.html">Working with LLVM</a></li><li><a class="tocitem" href="../devdocs/stdio.html">printf() and stdio in the Julia runtime</a></li><li><a class="tocitem" href="../devdocs/boundscheck.html">Bounds checking</a></li><li><a class="tocitem" href="../devdocs/locks.html">Proper maintenance and care of multi-threading locks</a></li><li><a class="tocitem" href="../devdocs/offset-arrays.html">Arrays with custom indices</a></li><li><a class="tocitem" href="../devdocs/require.html">Module loading</a></li><li><a class="tocitem" href="../devdocs/inference.html">Inference</a></li><li><a class="tocitem" href="../devdocs/ssair.html">Julia SSA-form IR</a></li><li><a class="tocitem" href="../devdocs/EscapeAnalysis.html"><code>EscapeAnalysis</code></a></li><li><a class="tocitem" href="../devdocs/aot.html">Ahead of Time Compilation</a></li><li><a class="tocitem" href="../devdocs/gc-sa.html">Static analyzer annotations for GC correctness in C code</a></li><li><a class="tocitem" href="../devdocs/gc.html">Garbage Collection in Julia</a></li><li><a class="tocitem" href="../devdocs/jit.html">JIT Design and Implementation</a></li><li><a class="tocitem" href="../devdocs/builtins.html">Core.Builtins</a></li><li><a class="tocitem" href="../devdocs/precompile_hang.html">Fixing precompilation hangs due to open tasks or IO</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6-2" type="checkbox"/><label class="tocitem" for="menuitem-6-2"><span class="docs-label">Developing/debugging Julia&#39;s C code</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../devdocs/backtraces.html">Reporting and analyzing crashes (segfaults)</a></li><li><a class="tocitem" href="../devdocs/debuggingtips.html">gdb debugging tips</a></li><li><a class="tocitem" href="../devdocs/valgrind.html">Using Valgrind with Julia</a></li><li><a class="tocitem" href="../devdocs/external_profilers.html">External Profiler Support</a></li><li><a class="tocitem" href="../devdocs/sanitizers.html">Sanitizer support</a></li><li><a class="tocitem" href="../devdocs/probes.html">Instrumenting Julia with DTrace, and bpftrace</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6-3" type="checkbox"/><label class="tocitem" for="menuitem-6-3"><span class="docs-label">Building Julia</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../devdocs/build/build.html">Building Julia (Detailed)</a></li><li><a class="tocitem" href="../devdocs/build/linux.html">Linux</a></li><li><a class="tocitem" href="../devdocs/build/macos.html">macOS</a></li><li><a class="tocitem" href="../devdocs/build/windows.html">Windows</a></li><li><a class="tocitem" href="../devdocs/build/freebsd.html">FreeBSD</a></li><li><a class="tocitem" href="../devdocs/build/arm.html">ARM (Linux)</a></li><li><a class="tocitem" href="../devdocs/build/distributing.html">Binary distributions</a></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Manual</a></li><li class="is-active"><a href="performance-tips.html">Performance Tips</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="performance-tips.html">Performance Tips</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaLang/julia" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaLang/julia/blob/master/doc/src/manual/performance-tips.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="man-performance-tips"><a class="docs-heading-anchor" href="#man-performance-tips">Performance Tips</a><a id="man-performance-tips-1"></a><a class="docs-heading-anchor-permalink" href="#man-performance-tips" title="Permalink"></a></h1><p>以下のセクションでは、Juliaコードをできるだけ速く実行するためのいくつかのテクニックを簡単に紹介します。</p><h2 id="Performance-critical-code-should-be-inside-a-function"><a class="docs-heading-anchor" href="#Performance-critical-code-should-be-inside-a-function">Performance critical code should be inside a function</a><a id="Performance-critical-code-should-be-inside-a-function-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-critical-code-should-be-inside-a-function" title="Permalink"></a></h2><p>パフォーマンスが重要なコードは、関数内に置くべきです。関数内のコードは、Juliaのコンパイラの動作により、トップレベルのコードよりもはるかに速く実行される傾向があります。</p><p>関数の使用はパフォーマンスだけでなく重要です。関数は再利用可能でテスト可能であり、どのステップが実行されているのか、入力と出力が何であるかを明確にします。<a href="style-guide.html#Write-functions,-not-just-scripts">Write functions, not just scripts</a>は、Juliaのスタイルガイドの推奨事項でもあります。</p><p>関数はグローバル変数に直接作用するのではなく、引数を取るべきです。次のポイントを参照してください。</p><h2 id="Avoid-untyped-global-variables"><a class="docs-heading-anchor" href="#Avoid-untyped-global-variables">Avoid untyped global variables</a><a id="Avoid-untyped-global-variables-1"></a><a class="docs-heading-anchor-permalink" href="#Avoid-untyped-global-variables" title="Permalink"></a></h2><p>未型付けのグローバル変数の値は、いつでも変更される可能性があり、その結果、型が変わることがあります。これにより、コンパイラがグローバル変数を使用するコードを最適化することが難しくなります。これは、型付き変数、つまりグローバルレベルの型エイリアスにも当てはまります。変数は可能な限りローカルであるか、関数に引数として渡されるべきです。</p><p>グローバル名は頻繁に定数であることがわかり、それをそのように宣言することでパフォーマンスが大幅に向上します：</p><pre><code class="language-julia hljs">const DEFAULT_VAL = 0</code></pre><p>グローバルが常に同じ型であることが知られている場合、<a href="variables-and-scoping.html#man-typed-globals">the type should be annotated</a>。</p><p>未型のグローバルの使用は、使用箇所でその型を注釈することによって最適化できます:</p><pre><code class="language-julia hljs">global x = rand(1000)

function loop_over_global()
    s = 0.0
    for i in x::Vector{Float64}
        s += i
    end
    return s
end</code></pre><p>関数に引数を渡すことは、より良いスタイルです。これにより、より再利用可能なコードが得られ、入力と出力が明確になります。</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>REPL内のすべてのコードはグローバルスコープで評価されるため、トップレベルで定義されて割り当てられた変数は<strong>グローバル</strong>変数になります。モジュール内のトップレベルスコープで定義された変数もグローバルです。</p></div></div><p>次のREPLセッションでは：</p><pre><code class="language-julia-repl hljs">julia&gt; x = 1.0</code></pre><p>は次のように等しいです：</p><pre><code class="language-julia-repl hljs">julia&gt; global x = 1.0</code></pre><p>したがって、以前に議論されたすべてのパフォーマンスの問題が適用されます。</p><h2 id="Measure-performance-with-[@time](@ref)-and-pay-attention-to-memory-allocation"><a class="docs-heading-anchor" href="#Measure-performance-with-[@time](@ref)-and-pay-attention-to-memory-allocation">Measure performance with <a href="profile.html#@time"><code>@time</code></a> and pay attention to memory allocation</a><a id="Measure-performance-with-[@time](@ref)-and-pay-attention-to-memory-allocation-1"></a><a class="docs-heading-anchor-permalink" href="#Measure-performance-with-[@time](@ref)-and-pay-attention-to-memory-allocation" title="Permalink"></a></h2><p>パフォーマンスを測定するための便利なツールは、<a href="profile.html#@time"><code>@time</code></a> マクロです。ここでは、上記のグローバル変数を使った例を繰り返しますが、今回は型アノテーションを削除しています：</p><pre><code class="language-julia-repl hljs">julia&gt; x = rand(1000);

julia&gt; function sum_global()
           s = 0.0
           for i in x
               s += i
           end
           return s
       end;

julia&gt; @time sum_global()
  0.011539 seconds (9.08 k allocations: 373.386 KiB, 98.69% compilation time)
523.0007221951678

julia&gt; @time sum_global()
  0.000091 seconds (3.49 k allocations: 70.156 KiB)
523.0007221951678</code></pre><p>最初の呼び出し（<code>@time sum_global()</code>）では、関数がコンパイルされます。（このセッションでまだ <a href="profile.html#@time"><code>@time</code></a> を使用していない場合、タイミングに必要な関数もコンパイルされます。）この実行の結果を真剣に受け取るべきではありません。2回目の実行では、時間を報告するだけでなく、かなりの量のメモリが割り当てられたことも示しています。ここでは、64ビット浮動小数点数のベクトル内のすべての要素の合計を計算しているだけなので、（ヒープ）メモリを割り当てる必要はないはずです。</p><p><code>@time</code> が報告するのは特に <em>ヒープ</em> アロケーションであり、これは通常、可変オブジェクトや可変サイズのコンテナ（例えば <code>Array</code> や <code>Dict</code>、文字列、または実行時にのみ型が知られる「型不安定」オブジェクト）を作成または成長させるために必要です。このようなメモリブロックを割り当てる（または解放する）には、libc への高価な関数呼び出し（例えば C の <code>malloc</code> を介して）が必要になる場合があり、ガーベジコレクションのために追跡されなければなりません。それに対して、数値（ビッグナムを除く）、タプル、そして不変の <code>struct</code> のような不変値は、スタックや CPU レジスタメモリに格納できるため、通常は「割り当てる」ことのパフォーマンスコストを心配する必要はありません。</p><p>予期しないメモリ割り当ては、ほぼ常にコードに何らかの問題がある兆候であり、通常は型の安定性の問題や多くの小さな一時配列を作成することに関連しています。そのため、割り当て自体に加えて、あなたの関数のために生成されたコードが最適から遠い可能性が非常に高いです。このような兆候を真剣に受け止め、以下のアドバイスに従ってください。</p><p>この特定のケースでは、メモリ割り当ては型が不安定なグローバル変数 <code>x</code> の使用によるものであるため、代わりに <code>x</code> を関数の引数として渡すと、もはやメモリを割り当てず（以下に報告されている残りの割り当てはグローバルスコープで <code>@time</code> マクロを実行したことによるものです）、最初の呼び出しの後は大幅に速くなります：</p><pre><code class="language-julia-repl hljs">julia&gt; x = rand(1000);

julia&gt; function sum_arg(x)
           s = 0.0
           for i in x
               s += i
           end
           return s
       end;

julia&gt; @time sum_arg(x)
  0.007551 seconds (3.98 k allocations: 200.548 KiB, 99.77% compilation time)
523.0007221951678

julia&gt; @time sum_arg(x)
  0.000006 seconds (1 allocation: 16 bytes)
523.0007221951678</code></pre><p><code>@time</code> マクロ自体をグローバルスコープで実行した場合に見られる 1 回のアロケーションです。代わりに関数内でタイミングを実行すると、実際にアロケーションが行われていないことがわかります：</p><pre><code class="language-julia-repl hljs">julia&gt; time_sum(x) = @time sum_arg(x);

julia&gt; time_sum(x)
  0.000002 seconds
523.0007221951678</code></pre><p>いくつかの状況では、関数がその操作の一部としてメモリを割り当てる必要があり、これが上記の単純な図を複雑にする可能性があります。そのような場合は、問題を診断するために以下の <a href="performance-tips.html#tools">tools</a> のいずれかを使用するか、割り当てをアルゴリズム的な側面から分離する関数のバージョンを書くことを検討してください（<a href="performance-tips.html#Pre-allocating-outputs">Pre-allocating outputs</a> を参照）。</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>より真剣なベンチマークを行う場合は、<a href="https://github.com/JuliaCI/BenchmarkTools.jl">BenchmarkTools.jl</a> パッケージを検討してください。このパッケージは、ノイズを減らすために関数を複数回評価するなど、他にもさまざまな機能を提供します。</p></div></div><h2 id="tools"><a class="docs-heading-anchor" href="#tools">Tools</a><a id="tools-1"></a><a class="docs-heading-anchor-permalink" href="#tools" title="Permalink"></a></h2><p>Juliaとそのパッケージエコシステムには、問題を診断し、コードのパフォーマンスを向上させるのに役立つツールが含まれています：</p><ul><li><a href="profile.html#Profiling">Profiling</a> は、実行中のコードのパフォーマンスを測定し、ボトルネックとなる行を特定することができます。複雑なプロジェクトの場合、<a href="https://github.com/timholy/ProfileView.jl">ProfileView</a> パッケージを使用すると、プロファイリング結果を視覚化するのに役立ちます。</li><li><a href="https://github.com/aviatesk/JET.jl">JET</a> パッケージは、コード内の一般的なパフォーマンス問題を見つけるのに役立ちます。</li><li>予期しない大きなメモリ割り当ては、<a href="profile.html#@time"><code>@time</code></a>、<a href="../base/base.html#Base.@allocated"><code>@allocated</code></a>、またはプロファイラ（ガーベジコレクションルーチンへの呼び出しを通じて）によって報告され、コードに問題がある可能性を示唆しています。割り当ての別の理由が見当たらない場合は、型の問題を疑ってください。また、<code>--track-allocation=user</code>オプションを使用してJuliaを起動し、結果の<code>*.mem</code>ファイルを調べることで、これらの割り当てが発生する場所に関する情報を確認できます。<a href="profile.html#Memory-allocation-analysis">Memory allocation analysis</a>を参照してください。</li><li><code>@code_warntype</code>は、型の不確実性をもたらす式を見つけるのに役立つコードの表現を生成します。以下の<a href="../stdlib/InteractiveUtils.html#InteractiveUtils.@code_warntype"><code>@code_warntype</code></a>を参照してください。</li></ul><h2 id="man-performance-abstract-container"><a class="docs-heading-anchor" href="#man-performance-abstract-container">Avoid containers with abstract type parameters</a><a id="man-performance-abstract-container-1"></a><a class="docs-heading-anchor-permalink" href="#man-performance-abstract-container" title="Permalink"></a></h2><p>パラメータ化された型、配列を含む場合、可能な限り抽象型でパラメータ化することは避けるのが最良です。</p><p>以下を考慮してください：</p><pre><code class="language-julia-repl hljs">julia&gt; a = Real[]
Real[]

julia&gt; push!(a, 1); push!(a, 2.0); push!(a, π)
3-element Vector{Real}:
 1
 2.0
 π = 3.1415926535897...</code></pre><p><code>a</code>は抽象型<a href="../base/numbers.html#Core.Real"><code>Real</code></a>の配列であるため、任意の<code>Real</code>値を保持できる必要があります。<code>Real</code>オブジェクトは任意のサイズと構造を持つことができるため、<code>a</code>は個別に割り当てられた<code>Real</code>オブジェクトへのポインタの配列として表現されなければなりません。しかし、もし<code>a</code>に同じ型の数値、例えば<a href="../base/numbers.html#Core.Float64"><code>Float64</code></a>のみを格納することを許可する場合、これらはより効率的に格納できます。</p><pre><code class="language-julia-repl hljs">julia&gt; a = Float64[]
Float64[]

julia&gt; push!(a, 1); push!(a, 2.0); push!(a,  π)
3-element Vector{Float64}:
 1.0
 2.0
 3.141592653589793</code></pre><p><code>a</code> に数値を割り当てると、これらは <code>Float64</code> に変換され、<code>a</code> は効率的に操作できる64ビット浮動小数点値の連続したブロックとして保存されます。</p><p>コンテナに抽象値型を使用せざるを得ない場合、ランタイム型チェックを避けるために <code>Any</code> でパラメータ化する方が良いことがあります。例えば、<code>IdDict{Any, Any}</code> は <code>IdDict{Type, Vector}</code> よりもパフォーマンスが向上します。</p><p><a href="types.html#Parametric-Types">Parametric Types</a>に関する議論も参照してください。</p><h2 id="Type-declarations"><a class="docs-heading-anchor" href="#Type-declarations">Type declarations</a><a id="Type-declarations-1"></a><a class="docs-heading-anchor-permalink" href="#Type-declarations" title="Permalink"></a></h2><p>多くのオプションの型宣言を持つ言語では、宣言を追加することがコードを速く実行する主な方法です。しかし、これはJuliaでは<em>ありません</em>。Juliaでは、コンパイラは一般的にすべての関数引数、ローカル変数、および式の型を知っています。ただし、宣言が役立つ特定のいくつかのケースがあります。</p><h3 id="Avoid-fields-with-abstract-type"><a class="docs-heading-anchor" href="#Avoid-fields-with-abstract-type">Avoid fields with abstract type</a><a id="Avoid-fields-with-abstract-type-1"></a><a class="docs-heading-anchor-permalink" href="#Avoid-fields-with-abstract-type" title="Permalink"></a></h3><p>フィールドの型を指定せずに型を宣言することができます：</p><pre><code class="language-julia-repl hljs">julia&gt; struct MyAmbiguousType
           a
       end</code></pre><p>これにより、<code>a</code> は任意の型であることができます。これはしばしば便利ですが、欠点もあります。<code>MyAmbiguousType</code> 型のオブジェクトの場合、コンパイラは高性能なコードを生成できません。その理由は、コンパイラがオブジェクトの値ではなく型を使用してコードの構築方法を決定するからです。残念ながら、<code>MyAmbiguousType</code> 型のオブジェクトについては、非常に少ない情報しか推測できません。</p><pre><code class="language-julia-repl hljs">julia&gt; b = MyAmbiguousType(&quot;Hello&quot;)
MyAmbiguousType(&quot;Hello&quot;)

julia&gt; c = MyAmbiguousType(17)
MyAmbiguousType(17)

julia&gt; typeof(b)
MyAmbiguousType

julia&gt; typeof(c)
MyAmbiguousType</code></pre><p><code>b</code> と <code>c</code> の値は同じ型ですが、メモリ内のデータの基礎となる表現は非常に異なります。フィールド <code>a</code> に数値のみを格納しても、<a href="../base/numbers.html#Core.UInt8"><code>UInt8</code></a> のメモリ表現が <a href="../base/numbers.html#Core.Float64"><code>Float64</code></a> と異なるという事実は、CPU がそれらを異なる種類の命令を使用して処理する必要があることを意味します。必要な情報が型に含まれていないため、そのような決定は実行時に行わなければなりません。これによりパフォーマンスが低下します。</p><p><code>a</code>の型を宣言することで、より良い結果を得ることができます。ここでは、<code>a</code>がいくつかの型のいずれかである可能性がある場合に焦点を当てており、その場合の自然な解決策はパラメータを使用することです。例えば：</p><pre><code class="language-julia-repl hljs">julia&gt; mutable struct MyType{T&lt;:AbstractFloat}
           a::T
       end</code></pre><p>これはより良い選択です。</p><pre><code class="language-julia-repl hljs">julia&gt; mutable struct MyStillAmbiguousType
           a::AbstractFloat
       end</code></pre><p>最初のバージョンは、ラッパーオブジェクトの型から <code>a</code> の型を指定するためです。例えば：</p><pre><code class="language-julia-repl hljs">julia&gt; m = MyType(3.2)
MyType{Float64}(3.2)

julia&gt; t = MyStillAmbiguousType(3.2)
MyStillAmbiguousType(3.2)

julia&gt; typeof(m)
MyType{Float64}

julia&gt; typeof(t)
MyStillAmbiguousType</code></pre><p>フィールド <code>a</code> の型は <code>m</code> の型から容易に決定できますが、<code>t</code> の型からは決定できません。実際、<code>t</code> ではフィールド <code>a</code> の型を変更することが可能です：</p><pre><code class="language-julia-repl hljs">julia&gt; typeof(t.a)
Float64

julia&gt; t.a = 4.5f0
4.5f0

julia&gt; typeof(t.a)
Float32</code></pre><p>対照的に、一度 <code>m</code> が構築されると、<code>m.a</code> の型は変更できません:</p><pre><code class="language-julia-repl hljs">julia&gt; m.a = 4.5f0
4.5f0

julia&gt; typeof(m.a)
Float64</code></pre><p><code>m</code>の型から<code>m.a</code>の型が知られているという事実と、その型が関数の途中で変わることができないという事実は、コンパイラが<code>m</code>のようなオブジェクトに対して高度に最適化されたコードを生成できることを可能にしますが、<code>t</code>のようなオブジェクトに対してはそうではありません。</p><p>もちろん、これはすべて <code>m</code> を具体的な型で構築した場合にのみ当てはまります。抽象型で明示的に構築することでこれを破ることができます：</p><pre><code class="language-julia-repl hljs">julia&gt; m = MyType{AbstractFloat}(3.2)
MyType{AbstractFloat}(3.2)

julia&gt; typeof(m.a)
Float64

julia&gt; m.a = 4.5f0
4.5f0

julia&gt; typeof(m.a)
Float32</code></pre><p>実用的な目的のために、そのようなオブジェクトは <code>MyStillAmbiguousType</code> のオブジェクトと同様に振る舞います。</p><p>単純な関数に対して生成されるコードの量を比較することは非常に教育的です。</p><pre><code class="language-julia hljs">func(m::MyType) = m.a+1</code></pre><p>使用して</p><pre><code class="language-julia hljs">code_llvm(func, Tuple{MyType{Float64}})
code_llvm(func, Tuple{MyType{AbstractFloat}})</code></pre><p>長さの理由から、結果はここに表示されていませんが、あなた自身で試してみることをお勧めします。最初のケースでは型が完全に指定されているため、コンパイラは実行時に型を解決するためのコードを生成する必要がありません。これにより、コードが短く、より高速になります。</p><p>完全にパラメータ化されていない型は抽象型のように振る舞うことも考慮すべきです。たとえば、完全に指定された <code>Array{T,n}</code> は具体的ですが、パラメータが与えられていない <code>Array</code> 自体は具体的ではありません:</p><pre><code class="language-julia-repl hljs">julia&gt; !isconcretetype(Array), !isabstracttype(Array), isstructtype(Array), !isconcretetype(Array{Int}), isconcretetype(Array{Int,1})
(true, true, true, true, true)</code></pre><p>この場合、<code>MyType</code>をフィールド<code>a::Array</code>で宣言するのではなく、フィールドを<code>a::Array{T,N}</code>または<code>a::A</code>として宣言する方が良いでしょう。ここで、<code>{T,N}</code>または<code>A</code>は<code>MyType</code>のパラメータです。</p><p>前のアドバイスは、構造体のフィールドが関数、またはより一般的には呼び出し可能なオブジェクトである場合に特に有用です。構造体を次のように定義するのは非常に魅力的です：</p><pre><code class="language-julia hljs">struct MyCallableWrapper
    f::Function
end</code></pre><p>しかし、<code>Function</code>は抽象型であるため、<code>wrapper.f</code>へのすべての呼び出しは、フィールド<code>f</code>へのアクセスの型不安定性のために動的ディスパッチを必要とします。代わりに、次のように書くべきです：</p><pre><code class="language-julia hljs">struct MyCallableWrapper{F}
    f::F
end</code></pre><p>ほぼ同じ動作を持ちながら、はるかに高速になります（型の不安定性が排除されるため）。<code>F&lt;:Function</code>を課さないことに注意してください。これは、<code>Function</code>のサブタイプでない呼び出し可能なオブジェクトもフィールド<code>f</code>に対して許可されることを意味します。</p><h3 id="Avoid-fields-with-abstract-containers"><a class="docs-heading-anchor" href="#Avoid-fields-with-abstract-containers">Avoid fields with abstract containers</a><a id="Avoid-fields-with-abstract-containers-1"></a><a class="docs-heading-anchor-permalink" href="#Avoid-fields-with-abstract-containers" title="Permalink"></a></h3><p>コンテナタイプにも同じベストプラクティスが適用されます：</p><pre><code class="language-julia-repl hljs">julia&gt; struct MySimpleContainer{A&lt;:AbstractVector}
           a::A
       end

julia&gt; struct MyAmbiguousContainer{T}
           a::AbstractVector{T}
       end

julia&gt; struct MyAlsoAmbiguousContainer
           a::Array
       end</code></pre><p>例えば：</p><pre><code class="language-julia-repl hljs">julia&gt; c = MySimpleContainer(1:3);

julia&gt; typeof(c)
MySimpleContainer{UnitRange{Int64}}

julia&gt; c = MySimpleContainer([1:3;]);

julia&gt; typeof(c)
MySimpleContainer{Vector{Int64}}

julia&gt; b = MyAmbiguousContainer(1:3);

julia&gt; typeof(b)
MyAmbiguousContainer{Int64}

julia&gt; b = MyAmbiguousContainer([1:3;]);

julia&gt; typeof(b)
MyAmbiguousContainer{Int64}

julia&gt; d = MyAlsoAmbiguousContainer(1:3);

julia&gt; typeof(d), typeof(d.a)
(MyAlsoAmbiguousContainer, Vector{Int64})

julia&gt; d = MyAlsoAmbiguousContainer(1:1.0:3);

julia&gt; typeof(d), typeof(d.a)
(MyAlsoAmbiguousContainer, Vector{Float64})
</code></pre><p><code>MySimpleContainer</code> の場合、オブジェクトはその型とパラメータによって完全に指定されているため、コンパイラは最適化された関数を生成できます。ほとんどの場合、これで十分でしょう。</p><p>コンパイラは現在、その仕事を完璧にこなすことができますが、<em>あなた</em>が <code>a</code> の <em>要素タイプ</em> に応じてコードが異なる動作をすることを望む場合があります。通常、これを達成する最良の方法は、特定の操作（ここでは <code>foo</code>）を別の関数にラップすることです：</p><pre><code class="language-julia-repl hljs">julia&gt; function sumfoo(c::MySimpleContainer)
           s = 0
           for x in c.a
               s += foo(x)
           end
           s
       end
sumfoo (generic function with 1 method)

julia&gt; foo(x::Integer) = x
foo (generic function with 1 method)

julia&gt; foo(x::AbstractFloat) = round(x)
foo (generic function with 2 methods)</code></pre><p>これにより、すべてのケースでコンパイラが最適化されたコードを生成できるようにしつつ、物事をシンプルに保つことができます。</p><p>ただし、<code>MySimpleContainer</code>のフィールド<code>a</code>の異なる要素タイプや<code>AbstractVector</code>の異なるバージョンの外部関数を宣言する必要がある場合があります。次のようにすることができます：</p><pre><code class="language-julia-repl hljs">julia&gt; function myfunc(c::MySimpleContainer{&lt;:AbstractArray{&lt;:Integer}})
           return c.a[1]+1
       end
myfunc (generic function with 1 method)

julia&gt; function myfunc(c::MySimpleContainer{&lt;:AbstractArray{&lt;:AbstractFloat}})
           return c.a[1]+2
       end
myfunc (generic function with 2 methods)

julia&gt; function myfunc(c::MySimpleContainer{Vector{T}}) where T &lt;: Integer
           return c.a[1]+3
       end
myfunc (generic function with 3 methods)</code></pre><pre><code class="language-julia-repl hljs">julia&gt; myfunc(MySimpleContainer(1:3))
2

julia&gt; myfunc(MySimpleContainer(1.0:3))
3.0

julia&gt; myfunc(MySimpleContainer([1:3;]))
4</code></pre><h3 id="Annotate-values-taken-from-untyped-locations"><a class="docs-heading-anchor" href="#Annotate-values-taken-from-untyped-locations">Annotate values taken from untyped locations</a><a id="Annotate-values-taken-from-untyped-locations-1"></a><a class="docs-heading-anchor-permalink" href="#Annotate-values-taken-from-untyped-locations" title="Permalink"></a></h3><p>データ構造は、任意の型の値を含む可能性があるため（<code>Array{Any}</code>型の配列）、扱うのが便利なことがよくあります。しかし、これらの構造を使用していて、要素の型がわかっている場合は、その知識をコンパイラと共有することが役立ちます。</p><pre><code class="language-julia hljs">function foo(a::Array{Any,1})
    x = a[1]::Int32
    b = x+1
    ...
end</code></pre><p>ここでは、<code>a</code>の最初の要素が<a href="../base/numbers.html#Core.Int32"><code>Int32</code></a>であることがわかりました。このように注釈を付けることで、値が期待される型でない場合にランタイムエラーが発生し、特定のバグを早期に検出できるという追加の利点があります。</p><p><code>a[1]</code>の型が正確に知られていない場合、<code>x</code>は<code>x = convert(Int32, a[1])::Int32</code>を使って宣言できます。<a href="../base/base.html#Base.convert"><code>convert</code></a>関数を使用することで、<code>a[1]</code>は<code>Int32</code>に変換可能な任意のオブジェクト（例えば<code>UInt8</code>）であることができ、型要件を緩めることでコードの汎用性が向上します。この文脈では、<code>convert</code>自体が型安定性を達成するために型注釈を必要とすることに注意してください。これは、コンパイラが関数のすべての引数の型が知られていない限り、関数の戻り値の型を推測できないためです。</p><p>型注釈は、型が抽象的であるか、実行時に構築される場合、パフォーマンスを向上させることはなく（実際には妨げることさえあります）、これはコンパイラが注釈を使用してその後のコードを特化できず、型チェック自体に時間がかかるためです。例えば、次のコードでは：</p><pre><code class="language-julia hljs">function nr(a, prec)
    ctype = prec == 32 ? Float32 : Float64
    b = Complex{ctype}(a)
    c = (b + 1.0f0)::Complex{ctype}
    abs(c)
end</code></pre><p><code>c</code>のアノテーションはパフォーマンスに悪影響を及ぼします。実行時に構築された型を含むパフォーマンスの良いコードを書くには、以下で説明する<a href="performance-tips.html#kernel-functions">function-barrier technique</a>を使用し、構築された型がカーネル関数の引数型の中に現れるようにして、カーネル操作がコンパイラによって適切に特化されるようにします。たとえば、上記のスニペットでは、<code>b</code>が構築されるとすぐに、別の関数<code>k</code>、すなわちカーネルに渡すことができます。たとえば、関数<code>k</code>が<code>b</code>を型パラメータ<code>T</code>の型<code>Complex{T}</code>の引数として宣言する場合、<code>k</code>内の代入文に現れる型アノテーションは次のようになります：</p><pre><code class="language-julia hljs">c = (b + 1.0f0)::Complex{T}</code></pre><p>パフォーマンスを妨げることはありません（しかし、助けることもありません）なぜなら、コンパイラは<code>k</code>がコンパイルされる時点で<code>c</code>の型を決定できるからです。</p><h3 id="Be-aware-of-when-Julia-avoids-specializing"><a class="docs-heading-anchor" href="#Be-aware-of-when-Julia-avoids-specializing">Be aware of when Julia avoids specializing</a><a id="Be-aware-of-when-Julia-avoids-specializing-1"></a><a class="docs-heading-anchor-permalink" href="#Be-aware-of-when-Julia-avoids-specializing" title="Permalink"></a></h3><p>ヒューリスティックとして、Juliaは特定の3つのケース、すなわち<code>Type</code>、<code>Function</code>、および<code>Vararg</code>において、引数の型パラメータに対して自動的に<a href="methods.html#man-method-specializations">specializing</a>を避けます。Juliaは引数がメソッド内で使用される場合には常に特化しますが、引数が別の関数に単に渡される場合には特化しません。これは通常、ランタイムでのパフォーマンスに影響を与えず、<a href="../devdocs/functions.html#compiler-efficiency-issues">improves compiler performance</a>。もしあなたのケースでランタイムにおいてパフォーマンスに影響がある場合は、メソッド宣言に型パラメータを追加することで特化をトリガーできます。以下はいくつかの例です：</p><p>これは専門的ではありません:</p><pre><code class="language-julia hljs">function f_type(t)  # or t::Type
    x = ones(t, 10)
    return sum(map(sin, x))
end</code></pre><p>しかし、これは次のことになります：</p><pre><code class="language-julia hljs">function g_type(t::Type{T}) where T
    x = ones(T, 10)
    return sum(map(sin, x))
end</code></pre><p>これらは専門化しません:</p><pre><code class="language-julia hljs">f_func(f, num) = ntuple(f, div(num, 2))
g_func(g::Function, num) = ntuple(g, div(num, 2))</code></pre><p>しかし、これは次のようになります：</p><pre><code class="language-julia hljs">h_func(h::H, num) where {H} = ntuple(h, div(num, 2))</code></pre><p>これは専門的ではありません:</p><pre><code class="language-julia hljs">f_vararg(x::Int...) = tuple(x...)</code></pre><p>しかし、これは次のことを行います：</p><pre><code class="language-julia hljs">g_vararg(x::Vararg{Int, N}) where {N} = tuple(x...)</code></pre><p>1つの型パラメータを導入するだけで、他の型が制約されていなくても特化を強制できます。たとえば、これは特化され、引数がすべて同じ型でない場合に便利です：</p><pre><code class="language-julia hljs">h_vararg(x::Vararg{Any, N}) where {N} = tuple(x...)</code></pre><p><a href="../stdlib/InteractiveUtils.html#InteractiveUtils.@code_typed"><code>@code_typed</code></a> とその仲間は、ジュリアが通常そのメソッド呼び出しを特化しない場合でも、常に特化されたコードを表示します。引数の型が変更されたときに特化が生成されるかどうかを確認したい場合は、<a href="../devdocs/ast.html#ast-lowered-method">method internals</a> をチェックする必要があります。つまり、<code>Base.specializations(@which f(...))</code> に問題の引数に対する特化が含まれているかどうかを確認します。</p><h2 id="Break-functions-into-multiple-definitions"><a class="docs-heading-anchor" href="#Break-functions-into-multiple-definitions">Break functions into multiple definitions</a><a id="Break-functions-into-multiple-definitions-1"></a><a class="docs-heading-anchor-permalink" href="#Break-functions-into-multiple-definitions" title="Permalink"></a></h2><p>関数を多くの小さな定義として書くことで、コンパイラは最も適切なコードを直接呼び出すことができ、さらにはインライン化することも可能です。</p><p>ここに「複合関数」の例がありますが、実際には複数の定義として書かれるべきです：</p><pre><code class="language-julia hljs">using LinearAlgebra

function mynorm(A)
    if isa(A, Vector)
        return sqrt(real(dot(A,A)))
    elseif isa(A, Matrix)
        return maximum(svdvals(A))
    else
        error(&quot;mynorm: invalid argument&quot;)
    end
end</code></pre><p>これをより簡潔かつ効率的に書くことができます:</p><pre><code class="language-julia hljs">mynorm(x::Vector) = sqrt(real(dot(x, x)))
mynorm(A::Matrix) = maximum(svdvals(A))</code></pre><p>ただし、コンパイラは <code>mynorm</code> の例として書かれたコードの無駄な分岐を最適化するのが非常に効率的であることに注意する必要があります。</p><h2 id="Write-&quot;type-stable&quot;-functions"><a class="docs-heading-anchor" href="#Write-&quot;type-stable&quot;-functions">Write &quot;type-stable&quot; functions</a><a id="Write-&quot;type-stable&quot;-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Write-&quot;type-stable&quot;-functions" title="Permalink"></a></h2><p>可能な場合は、関数が常に同じ型の値を返すことを保証するのが役立ちます。次の定義を考えてみてください：</p><pre><code class="language-julia hljs">pos(x) = x &lt; 0 ? 0 : x</code></pre><p>このように見えるかもしれませんが、問題は <code>0</code> が整数（型 <code>Int</code>）であり、<code>x</code> は任意の型である可能性があることです。したがって、<code>x</code> の値に応じて、この関数は2つの型のいずれかの値を返す可能性があります。この動作は許可されており、場合によっては望ましいこともあります。しかし、次のように簡単に修正できます：</p><pre><code class="language-julia hljs">pos(x) = x &lt; 0 ? zero(x) : x</code></pre><p><a href="../base/numbers.html#Base.oneunit"><code>oneunit</code></a> 関数と、より一般的な <a href="../base/base.html#Base.oftype"><code>oftype(x, y)</code></a> 関数があります。これらは、<code>y</code> を <code>x</code> の型に変換して返します。</p><h2 id="Avoid-changing-the-type-of-a-variable"><a class="docs-heading-anchor" href="#Avoid-changing-the-type-of-a-variable">Avoid changing the type of a variable</a><a id="Avoid-changing-the-type-of-a-variable-1"></a><a class="docs-heading-anchor-permalink" href="#Avoid-changing-the-type-of-a-variable" title="Permalink"></a></h2><p>関数内で繰り返し使用される変数に対しても、類似の「型安定性」問題が存在します：</p><pre><code class="language-julia hljs">function foo()
    x = 1
    for i = 1:10
        x /= rand()
    end
    return x
end</code></pre><p>ローカル変数 <code>x</code> は整数として始まり、1回のループの反復後に浮動小数点数になります（<a href="../base/math.html#Base.:/"><code>/</code></a> 演算子の結果）。これにより、コンパイラがループの本体を最適化するのが難しくなります。いくつかの修正方法があります：</p><ul><li><code>x</code>を<code>x = 1.0</code>で初期化します。</li><li><code>x::Float64 = 1</code> として <code>x</code> の型を明示的に宣言します。</li><li><code>x = oneunit(Float64)</code>の明示的な変換を使用します。</li><li>最初のループの反復を <code>x = 1 / rand()</code> で初期化し、その後 <code>for i = 2:10</code> でループします。</li></ul><h2 id="kernel-functions"><a class="docs-heading-anchor" href="#kernel-functions">Separate kernel functions (aka, function barriers)</a><a id="kernel-functions-1"></a><a class="docs-heading-anchor-permalink" href="#kernel-functions" title="Permalink"></a></h2><p>多くの関数は、いくつかのセットアップ作業を行い、その後、コア計算を実行するために多くの反復を行うというパターンに従います。可能であれば、これらのコア計算を別の関数に分けるのが良いアイデアです。たとえば、以下の作り話の関数は、ランダムに選ばれたタイプの配列を返します：</p><pre><code class="language-julia-repl hljs">julia&gt; function strange_twos(n)
           a = Vector{rand(Bool) ? Int64 : Float64}(undef, n)
           for i = 1:n
               a[i] = 2
           end
           return a
       end;

julia&gt; strange_twos(3)
3-element Vector{Int64}:
 2
 2
 2</code></pre><p>これは次のように書かれるべきです：</p><pre><code class="language-julia-repl hljs">julia&gt; function fill_twos!(a)
           for i = eachindex(a)
               a[i] = 2
           end
       end;

julia&gt; function strange_twos(n)
           a = Vector{rand(Bool) ? Int64 : Float64}(undef, n)
           fill_twos!(a)
           return a
       end;

julia&gt; strange_twos(3)
3-element Vector{Int64}:
 2
 2
 2</code></pre><p>Juliaのコンパイラは、関数の境界で引数の型に特化したコードを生成します。そのため、元の実装ではループ中に<code>a</code>の型がわかりません（ランダムに選ばれるため）。したがって、2番目のバージョンは一般的に速く、内部ループは<code>fill_twos!</code>の一部として異なる型の<code>a</code>に対して再コンパイルできます。</p><p>第二の形式は、しばしばより良いスタイルであり、コードの再利用を促進することができます。</p><p>このパターンは、Julia Baseのいくつかの場所で使用されています。例えば、<code>vcat</code>や<code>hcat</code>を参照してください。<a href="https://github.com/JuliaLang/julia/blob/40fe264f4ffaa29b749bcf42239a89abdcbba846/base/abstractarray.jl#L1205-L1206"><code>abstractarray.jl</code></a>や、<a href="../base/arrays.html#Base.fill!"><code>fill!</code></a>関数を参照してください。この関数を使用する代わりに、自分の<code>fill_twos!</code>を書くこともできました。</p><p><code>strange_twos</code>のような関数は、整数、浮動小数点数、文字列、またはその他の何かを含む可能性のある入力ファイルから読み込まれたデータなど、不確定な型のデータを扱うときに発生します。</p><h2 id="man-performance-value-type"><a class="docs-heading-anchor" href="#man-performance-value-type">Types with values-as-parameters</a><a id="man-performance-value-type-1"></a><a class="docs-heading-anchor-permalink" href="#man-performance-value-type" title="Permalink"></a></h2><p><code>N</code>次元配列を作成したいとしましょう。各軸のサイズが3の配列です。このような配列は次のように作成できます：</p><pre><code class="language-julia-repl hljs">julia&gt; A = fill(5.0, (3, 3))
3×3 Matrix{Float64}:
 5.0  5.0  5.0
 5.0  5.0  5.0
 5.0  5.0  5.0</code></pre><p>このアプローチは非常に効果的です：コンパイラは、<code>A</code> が <code>Array{Float64,2}</code> であることを理解できます。なぜなら、フィル値の型（<code>5.0::Float64</code>）と次元（<code>(3, 3)::NTuple{2,Int}</code>）を知っているからです。これは、コンパイラが同じ関数内での <code>A</code> の将来の使用に対して非常に効率的なコードを生成できることを意味します。</p><p>しかし、今、任意の次元で3×3×...の配列を作成する関数を書きたいとしましょう。関数を書くことに誘惑されるかもしれません。</p><pre><code class="language-julia-repl hljs">julia&gt; function array3(fillval, N)
           fill(fillval, ntuple(d-&gt;3, N))
       end
array3 (generic function with 1 method)

julia&gt; array3(5.0, 2)
3×3 Matrix{Float64}:
 5.0  5.0  5.0
 5.0  5.0  5.0
 5.0  5.0  5.0</code></pre><p>これは機能しますが（<code>@code_warntype array3(5.0, 2)</code>を使用して自分で確認できます）、問題は出力タイプを推論できないことです。引数<code>N</code>は<code>Int</code>型の<em>値</em>であり、型推論はその値を事前に予測することができません。これは、この関数の出力を使用するコードが保守的でなければならず、<code>A</code>への各アクセス時に型をチェックする必要があることを意味します。そのようなコードは非常に遅くなります。</p><p>今、このような問題を解決する非常に良い方法は、<a href="performance-tips.html#kernel-functions">function-barrier technique</a>を使用することです。しかし、場合によっては、型の不安定性を完全に排除したいことがあります。そのような場合の一つのアプローチは、次元をパラメータとして渡すことです。例えば、<code>Val{T}()</code>を通じて（<a href="types.html#&quot;Value-types&quot;">&quot;Value types&quot;</a>を参照）。</p><pre><code class="language-julia-repl hljs">julia&gt; function array3(fillval, ::Val{N}) where N
           fill(fillval, ntuple(d-&gt;3, Val(N)))
       end
array3 (generic function with 1 method)

julia&gt; array3(5.0, Val(2))
3×3 Matrix{Float64}:
 5.0  5.0  5.0
 5.0  5.0  5.0
 5.0  5.0  5.0</code></pre><p>Juliaは、第二引数として<code>Val{::Int}</code>インスタンスを受け取る特別なバージョンの<code>ntuple</code>を持っています。<code>N</code>を型パラメータとして渡すことで、その「値」をコンパイラに知らしめます。したがって、このバージョンの<code>array3</code>は、コンパイラが戻り値の型を予測できるようにします。</p><p>しかし、そのような技術を利用することは驚くほど微妙です。たとえば、次のような関数から <code>array3</code> を呼び出しても、何の役にも立ちません:</p><pre><code class="language-julia hljs">function call_array3(fillval, n)
    A = array3(fillval, Val(n))
end</code></pre><p>ここでは、同じ問題を再び作成しています：コンパイラは <code>n</code> が何であるかを推測できないため、<code>Val(n)</code> の<em>型</em>がわかりません。<code>Val</code> を使用しようとしますが、誤って使用すると、多くの状況でパフォーマンスが<em>悪化</em>する可能性があります。（上記のようなコードは、カーネル関数をより効率的にするために、実質的に <code>Val</code> を関数バリアトリックと組み合わせている状況でのみ使用されるべきです。）</p><p><code>Val</code>の正しい使用例は次のとおりです：</p><pre><code class="language-julia hljs">function filter3(A::AbstractArray{T,N}) where {T,N}
    kernel = array3(1, Val(N))
    filter(A, kernel)
end</code></pre><p>この例では、<code>N</code>がパラメータとして渡されるため、その「値」はコンパイラに知られています。基本的に、<code>Val(T)</code>は<code>T</code>がハードコーディングされたリテラル（<code>Val(3)</code>）であるか、すでに型ドメインで指定されている場合にのみ機能します。</p><h2 id="The-dangers-of-abusing-multiple-dispatch-(aka,-more-on-types-with-values-as-parameters)"><a class="docs-heading-anchor" href="#The-dangers-of-abusing-multiple-dispatch-(aka,-more-on-types-with-values-as-parameters)">The dangers of abusing multiple dispatch (aka, more on types with values-as-parameters)</a><a id="The-dangers-of-abusing-multiple-dispatch-(aka,-more-on-types-with-values-as-parameters)-1"></a><a class="docs-heading-anchor-permalink" href="#The-dangers-of-abusing-multiple-dispatch-(aka,-more-on-types-with-values-as-parameters)" title="Permalink"></a></h2><p>一度複数ディスパッチの重要性を理解すると、すべてにそれを使おうとする傾向があるのは理解できます。例えば、情報を保存するためにそれを使うことを想像するかもしれません。</p><pre><code class="nohighlight hljs">struct Car{Make, Model}
    year::Int
    ...more fields...
end</code></pre><p>そして、<code>Car{:Honda,:Accord}(year, args...)</code>のようなオブジェクトにディスパッチします。</p><p>これは、次のいずれかが真である場合に価値があるかもしれません：</p><ul><li>各 <code>Car</code> に対して CPU 集中型の処理が必要であり、コンパイル時に <code>Make</code> と <code>Model</code> を知っていると、効率が大幅に向上します。また、使用される異なる <code>Make</code> または <code>Model</code> の総数がそれほど多くない場合に限ります。</li><li>同じタイプの <code>Car</code> の均質なリストを処理する必要があるため、すべてを <code>Array{Car{:Honda,:Accord},N}</code> に格納できます。</li></ul><p>後者が成り立つとき、そのような均質な配列を処理する関数は生産的に特化できます：Juliaは各要素の型を事前に知っているため（コンテナ内のすべてのオブジェクトが同じ具体的な型を持つ）、関数がコンパイルされる際に正しいメソッド呼び出しを「参照」できるため（実行時にチェックする必要がなく）、リスト全体を処理するための効率的なコードを生成できます。</p><p>これらが成り立たない場合、利益を得られない可能性が高く、さらに「型の組み合わせ爆発」が逆効果になることがあります。もし <code>items[i+1]</code> が <code>item[i]</code> とは異なる型であれば、Julia は実行時に型を調べ、メソッドテーブルで適切なメソッドを検索し、型の交差を通じてどれが一致するかを決定し、まだJITコンパイルされていない場合はそれを行い、そして呼び出しを行います。要するに、あなたは完全な型システムとJITコンパイルの仕組みに、自分のコード内でスイッチ文や辞書の検索を実行させるように求めているのです。</p><p>いくつかのランタイムベンチマークが、(1) タイプディスパッチ、(2) 辞書ルックアップ、(3) &quot;スイッチ&quot; ステートメントを比較しています。詳細は <a href="https://groups.google.com/forum/#!msg/julia-users/jUMu9A3QKQQ/qjgVWr7vAwAJ">on the mailing list</a> を参照してください。</p><p>おそらく、実行時の影響よりも悪いのはコンパイル時の影響です。Juliaは、異なる <code>Car{Make, Model}</code> ごとに特化した関数をコンパイルします。もし何百、何千ものそのような型がある場合、カスタムの <code>get_year</code> 関数から、Julia Baseの一般的な <code>push!</code> 関数まで、そのようなオブジェクトをパラメータとして受け取るすべての関数に対して、何百、何千ものバリアントがコンパイルされます。これらのそれぞれが、コンパイルされたコードのキャッシュのサイズ、内部のメソッドリストの長さなどを増加させます。値をパラメータとして使用することに対する過剰な熱意は、簡単に膨大なリソースを浪費する可能性があります。</p><h2 id="man-performance-column-major"><a class="docs-heading-anchor" href="#man-performance-column-major">Access arrays in memory order, along columns</a><a id="man-performance-column-major-1"></a><a class="docs-heading-anchor-permalink" href="#man-performance-column-major" title="Permalink"></a></h2><p>Juliaの多次元配列は列優先順序で格納されます。これは、配列が1列ずつ積み重ねられることを意味します。これは、以下に示すように<code>vec</code>関数または構文<code>[:]</code>を使用して確認できます（配列が<code>[1 3 2 4]</code>の順序であることに注意してください、<code>[1 2 3 4]</code>ではありません）：</p><pre><code class="language-julia-repl hljs">julia&gt; x = [1 2; 3 4]
2×2 Matrix{Int64}:
 1  2
 3  4

julia&gt; x[:]
4-element Vector{Int64}:
 1
 3
 2
 4</code></pre><p>この配列の順序付けの規則は、Fortran、Matlab、Rなどの多くの言語で一般的です（いくつかの例を挙げると）。列優先順序の代替は行優先順序であり、これはCやPython（<code>numpy</code>）などの他の言語で採用されている規則です。配列の順序を覚えておくことは、配列をループする際に重要なパフォーマンス効果を持つ可能性があります。覚えておくべきルールは、列優先配列では最初のインデックスが最も速く変化するということです。基本的に、これは内側のループインデックスがスライス式の最初に現れる場合、ループが速くなることを意味します。<code>:</code>を使って配列にインデックスを付けることは、特定の次元内のすべての要素に反復的にアクセスする暗黙のループであることを念頭に置いてください。例えば、列を抽出する方が行を抽出するよりも速い場合があります。</p><p>次のような作り話の例を考えてみましょう。<a href="../base/arrays.html#Base.Vector"><code>Vector</code></a>を受け取り、入力ベクトルのコピーで埋められた正方形<a href="../base/arrays.html#Base.Matrix"><code>Matrix</code></a>を返す関数を書きたいとします。行または列のどちらにこれらのコピーが埋められるかは重要ではないと仮定します（おそらく、残りのコードはそれに応じて簡単に適応できるでしょう）。少なくとも4つの方法（組み込みの<a href="../base/arrays.html#Base.repeat"><code>repeat</code></a>への推奨される呼び出しに加えて）でこれを実現できると考えられます。</p><pre><code class="language-julia hljs">function copy_cols(x::Vector{T}) where T
    inds = axes(x, 1)
    out = similar(Array{T}, inds, inds)
    for i = inds
        out[:, i] = x
    end
    return out
end

function copy_rows(x::Vector{T}) where T
    inds = axes(x, 1)
    out = similar(Array{T}, inds, inds)
    for i = inds
        out[i, :] = x
    end
    return out
end

function copy_col_row(x::Vector{T}) where T
    inds = axes(x, 1)
    out = similar(Array{T}, inds, inds)
    for col = inds, row = inds
        out[row, col] = x[row]
    end
    return out
end

function copy_row_col(x::Vector{T}) where T
    inds = axes(x, 1)
    out = similar(Array{T}, inds, inds)
    for row = inds, col = inds
        out[row, col] = x[col]
    end
    return out
end</code></pre><p>これから、同じランダムな <code>10000</code> x <code>1</code> の入力ベクトルを使用して、これらの関数のそれぞれの実行時間を計測します。</p><pre><code class="language-julia-repl hljs">julia&gt; x = randn(10000);

julia&gt; fmt(f) = println(rpad(string(f)*&quot;: &quot;, 14, &#39; &#39;), @elapsed f(x))

julia&gt; map(fmt, [copy_cols, copy_rows, copy_col_row, copy_row_col]);
copy_cols:    0.331706323
copy_rows:    1.799009911
copy_col_row: 0.415630047
copy_row_col: 1.721531501</code></pre><p><code>copy_cols</code> は <code>copy_rows</code> よりもはるかに速いことに注意してください。これは、<code>copy_cols</code> が <code>Matrix</code> の列ベースのメモリレイアウトを尊重し、1 列ずつ埋めるため、予想されることです。さらに、<code>copy_col_row</code> は <code>copy_row_col</code> よりもはるかに速いです。これは、スライス式に最初に現れる要素が最も内側のループと結びつくべきという私たちの経験則に従っているためです。</p><h2 id="Pre-allocating-outputs"><a class="docs-heading-anchor" href="#Pre-allocating-outputs">Pre-allocating outputs</a><a id="Pre-allocating-outputs-1"></a><a class="docs-heading-anchor-permalink" href="#Pre-allocating-outputs" title="Permalink"></a></h2><p>もしあなたの関数が <code>Array</code> や他の複雑な型を返す場合、メモリを割り当てる必要があるかもしれません。残念ながら、しばしば割り当てとその逆であるガーベジコレクションは、重大なボトルネックとなります。</p><p>時には、各関数呼び出しごとにメモリを割り当てる必要を回避するために、出力を事前に割り当てることができます。簡単な例として、比較してください。</p><pre><code class="language-julia-repl hljs">julia&gt; function xinc(x)
           return [x, x+1, x+2]
       end;

julia&gt; function loopinc()
           y = 0
           for i = 1:10^7
               ret = xinc(i)
               y += ret[2]
           end
           return y
       end;</code></pre><p>with</p><pre><code class="language-julia-repl hljs">julia&gt; function xinc!(ret::AbstractVector{T}, x::T) where T
           ret[1] = x
           ret[2] = x+1
           ret[3] = x+2
           nothing
       end;

julia&gt; function loopinc_prealloc()
           ret = Vector{Int}(undef, 3)
           y = 0
           for i = 1:10^7
               xinc!(ret, i)
               y += ret[2]
           end
           return y
       end;</code></pre><p>タイミング結果:</p><pre><code class="language-julia-repl hljs">julia&gt; @time loopinc()
  0.529894 seconds (40.00 M allocations: 1.490 GiB, 12.14% gc time)
50000015000000

julia&gt; @time loopinc_prealloc()
  0.030850 seconds (6 allocations: 288 bytes)
50000015000000</code></pre><p>プレアロケーションには他にも利点があります。たとえば、呼び出し元がアルゴリズムからの「出力」タイプを制御できるようにすることです。上記の例では、<code>SubArray</code>を渡すこともできましたが、<a href="../base/arrays.html#Core.Array"><code>Array</code></a>を渡すことも可能でした。</p><p>極端に進めると、事前割り当てはコードを醜くする可能性があるため、パフォーマンス測定といくつかの判断が必要になる場合があります。しかし、「ベクトル化された」（要素ごとの）関数の場合、便利な構文 <code>x .= f.(y)</code> を使用して、テンポラリ配列なしでループを融合させたインプレース操作を行うことができます（詳細は <a href="functions.html#man-vectorized">dot syntax for vectorizing functions</a> を参照してください）。</p><h2 id="man-perftips-mutablearithmetics"><a class="docs-heading-anchor" href="#man-perftips-mutablearithmetics">Use <code>MutableArithmetics</code> for more control over allocation for mutable arithmetic types</a><a id="man-perftips-mutablearithmetics-1"></a><a class="docs-heading-anchor-permalink" href="#man-perftips-mutablearithmetics" title="Permalink"></a></h2><p>いくつかの <a href="../base/numbers.html#Core.Number"><code>Number</code></a> サブタイプ、例えば <a href="../base/numbers.html#Base.GMP.BigInt"><code>BigInt</code></a> や <a href="../base/numbers.html#Base.MPFR.BigFloat"><code>BigFloat</code></a> は、<a href="../base/base.html#mutable struct"><code>mutable struct</code></a> タイプとして実装されるか、可変コンポーネントを持つ場合があります。Julia <code>Base</code> の算術インターフェースは、通常、効率よりも便利さを選択するため、そのような場合にナイーブな方法で使用すると最適でないパフォーマンスを引き起こす可能性があります。一方で、<a href="https://juliahub.com/ui/Packages/General/MutableArithmetics"><code>MutableArithmetics</code></a> パッケージの抽象化は、そのようなタイプの可変性を利用して、必要な分だけを割り当てる高速なコードを書くことを可能にします。<code>MutableArithmetics</code> は、必要に応じて可変算術型の値を明示的にコピーすることも可能にします。<code>MutableArithmetics</code> はユーザーパッケージであり、Juliaプロジェクトとは提携していません。</p><h2 id="More-dots:-Fuse-vectorized-operations"><a class="docs-heading-anchor" href="#More-dots:-Fuse-vectorized-operations">More dots: Fuse vectorized operations</a><a id="More-dots:-Fuse-vectorized-operations-1"></a><a class="docs-heading-anchor-permalink" href="#More-dots:-Fuse-vectorized-operations" title="Permalink"></a></h2><p>ジュリアには、任意のスカラー関数を「ベクトル化された」関数呼び出しに、任意の演算子を「ベクトル化された」演算子に変換する特別な <a href="functions.html#man-vectorized">dot syntax</a> があります。この特別なプロパティは、ネストされた「ドット呼び出し」が<em>融合</em>されることです：これは、構文レベルで単一のループに結合され、一時的な配列を割り当てることなく行われます。<code>.=</code> や類似の代入演算子を使用すると、結果は事前に割り当てられた配列にインプレースで保存することもできます（上記を参照）。</p><p>線形代数の文脈では、<code>vector + vector</code> や <code>vector * scalar</code> のような演算が定義されているにもかかわらず、代わりに <code>vector .+ vector</code> や <code>vector .* scalar</code> を使用することが有利な場合があります。なぜなら、結果として得られるループが周囲の計算と融合できるからです。例えば、次の2つの関数を考えてみましょう：</p><pre><code class="language-julia-repl hljs">julia&gt; f(x) = 3x.^2 + 4x + 7x.^3;

julia&gt; fdot(x) = @. 3x^2 + 4x + 7x^3; # equivalent to 3 .* x.^2 .+ 4 .* x .+ 7 .* x.^3</code></pre><p>両方の <code>f</code> と <code>fdot</code> は同じことを計算します。しかし、<code>fdot</code>（<a href="../base/arrays.html#Base.Broadcast.@__dot__"><code>@.</code></a> マクロを使って定義された）は、配列に適用した場合、著しく速くなります：</p><pre><code class="language-julia-repl hljs">julia&gt; x = rand(10^6);

julia&gt; @time f(x);
  0.019049 seconds (16 allocations: 45.777 MiB, 18.59% gc time)

julia&gt; @time fdot(x);
  0.002790 seconds (6 allocations: 7.630 MiB)

julia&gt; @time f.(x);
  0.002626 seconds (8 allocations: 7.630 MiB)</code></pre><p>つまり、<code>fdot(x)</code>は<code>f(x)</code>の10倍速く、メモリを1/6しか使用しません。なぜなら、<code>f(x)</code>の各<code>*</code>および<code>+</code>操作は新しい一時配列を割り当て、別のループで実行されるからです。この例では、<code>f.(x)</code>は<code>fdot(x)</code>と同じくらい速いですが、多くの文脈では、各ベクトル化操作のために別の関数を定義するよりも、式にいくつかのドットを散りばめる方が便利です。</p><h2 id="man-performance-unfuse"><a class="docs-heading-anchor" href="#man-performance-unfuse">Fewer dots: Unfuse certain intermediate broadcasts</a><a id="man-performance-unfuse-1"></a><a class="docs-heading-anchor-permalink" href="#man-performance-unfuse" title="Permalink"></a></h2><p>上記のドットループ融合は、高性能な操作を表現するための簡潔で慣用的なコードを可能にします。しかし、融合された操作はブロードキャストの各イテレーションで計算されることを忘れないことが重要です。これは、特に合成または多次元ブロードキャストが存在する場合に、ドット呼び出しを含む式が意図したよりも多くの回数関数を計算している可能性があることを意味します。例えば、行のユークリッドノルムが1のランダム行列を構築したいとしましょう。その場合、次のようなコードを書くかもしれません：</p><pre><code class="nohighlight hljs">julia&gt; x = rand(1000, 1000);

julia&gt; d = sum(abs2, x; dims=2);

julia&gt; @time x ./= sqrt.(d);
  0.002049 seconds (4 allocations: 96 bytes)</code></pre><p>これで動作します。ただし、この式は実際には行 <code>x[i, :]</code> の <em>すべての</em> 要素に対して <code>sqrt(d[i])</code> を再計算するため、必要以上に多くの平方根が計算されることになります。ブロードキャストがどのインデックスを反復するかを正確に確認するには、融合式の引数に対して <code>Broadcast.combine_axes</code> を呼び出すことができます。これにより、エントリが反復の軸に対応する範囲のタプルが返されます。これらの範囲の長さの積が、融合操作への呼び出しの総数になります。</p><p>それにより、ブロードキャスト式のいくつかのコンポーネントが軸に沿って定数である場合—前の例での第二次元に沿った<code>sqrt</code>のように—、それらのコンポーネントを強制的に「非融合」させることによってパフォーマンスの向上の可能性があります。つまり、ブロードキャストされた操作の結果を事前に割り当て、その定数軸に沿ってキャッシュされた値を再利用することです。そのような潜在的なアプローチのいくつかは、一時変数を使用すること、ドット式のコンポーネントを<code>identity</code>でラップすること、または同等の内在的にベクトル化された（しかし非融合の）関数を使用することです。</p><pre><code class="nohighlight hljs">julia&gt; @time let s = sqrt.(d); x ./= s end;
  0.000809 seconds (5 allocations: 8.031 KiB)

julia&gt; @time x ./= identity(sqrt.(d));
  0.000608 seconds (5 allocations: 8.031 KiB)

julia&gt; @time x ./= map(sqrt, d);
  0.000611 seconds (4 allocations: 8.016 KiB)</code></pre><p>これらのオプションのいずれも、割り当てのコストで約3倍のスピードアップをもたらします。大きなブロードキャスト可能なデータに対しては、このスピードアップは漸近的に非常に大きくなる可能性があります。</p><h2 id="man-performance-views"><a class="docs-heading-anchor" href="#man-performance-views">Consider using views for slices</a><a id="man-performance-views-1"></a><a class="docs-heading-anchor-permalink" href="#man-performance-views" title="Permalink"></a></h2><p>Juliaでは、配列の「スライス」式 <code>array[1:5, :]</code> は、そのデータのコピーを作成します（代入の左辺にある場合を除き、ここでは <code>array[1:5, :] = ...</code> がその部分に対してインプレースで代入します）。スライスに対して多くの操作を行う場合、より小さな連続したコピーで作業する方が、元の配列にインデックスを付けるよりも効率的であるため、パフォーマンスにとって良いことがあります。一方で、スライスに対していくつかの単純な操作を行うだけの場合、割り当てとコピー操作のコストはかなり大きくなる可能性があります。</p><p>配列の「ビュー」を作成する代替手段があります。これは、実際に元の配列のデータをそのまま参照する配列オブジェクト（<code>SubArray</code>）であり、コピーを作成することなく行われます。（ビューに書き込むと、元の配列のデータも変更されます。）これは、<a href="../base/arrays.html#Base.view"><code>view</code></a>を呼び出すことで個々のスライスに対して行うことができます。また、より簡単には、<a href="../base/arrays.html#Base.@views"><code>@views</code></a>をその式の前に置くことで、全体の式やコードブロックに対して行うことができます。例えば：</p><pre><code class="language-julia-repl hljs">julia&gt; fcopy(x) = sum(x[2:end-1]);

julia&gt; @views fview(x) = sum(x[2:end-1]);

julia&gt; x = rand(10^6);

julia&gt; @time fcopy(x);
  0.003051 seconds (3 allocations: 7.629 MB)

julia&gt; @time fview(x);
  0.001020 seconds (1 allocation: 16 bytes)</code></pre><p><code>fview</code>バージョンの関数の3倍のスピードアップとメモリ割り当ての減少の両方に注意してください。</p><h2 id="Copying-data-is-not-always-bad"><a class="docs-heading-anchor" href="#Copying-data-is-not-always-bad">Copying data is not always bad</a><a id="Copying-data-is-not-always-bad-1"></a><a class="docs-heading-anchor-permalink" href="#Copying-data-is-not-always-bad" title="Permalink"></a></h2><p>配列はメモリ内に連続して格納されており、CPUのベクトル化やキャッシュによるメモリアクセスの削減に寄与します。これらは、配列に列優先順序でアクセスすることが推奨される理由と同じです（上記参照）。不規則なアクセスパターンや非連続的なビューは、非連続的なメモリアクセスのために配列の計算を大幅に遅くする可能性があります。</p><p>不規則にアクセスされるデータを連続した配列にコピーしてから繰り返しアクセスすることで、大きな速度向上が得られることがあります。以下の例では、行列がランダムにシャッフルされたインデックスでアクセスされた後に乗算されます。プレーン配列にコピーすることで、コピーと割り当ての追加コストがあっても乗算が高速化されます。</p><pre><code class="language-julia-repl hljs">julia&gt; using Random

julia&gt; A = randn(3000, 3000);

julia&gt; x = randn(2000);

julia&gt; inds = shuffle(1:3000)[1:2000];

julia&gt; function iterated_neural_network(A, x, depth)
           for _ in 1:depth
               x .= max.(0, A * x)
           end
           argmax(x)
       end

julia&gt; @time iterated_neural_network(view(A, inds, inds), x, 10)
  0.324903 seconds (12 allocations: 157.562 KiB)
1569

julia&gt; @time iterated_neural_network(A[inds, inds], x, 10)
  0.054576 seconds (13 allocations: 30.671 MiB, 13.33% gc time)
1569</code></pre><p>十分なメモリがある場合、ビューを配列にコピーするコストは、連続した配列で繰り返し行う行列の乗算による速度向上によって上回られます。</p><h2 id="Consider-StaticArrays.jl-for-small-fixed-size-vector/matrix-operations"><a class="docs-heading-anchor" href="#Consider-StaticArrays.jl-for-small-fixed-size-vector/matrix-operations">Consider StaticArrays.jl for small fixed-size vector/matrix operations</a><a id="Consider-StaticArrays.jl-for-small-fixed-size-vector/matrix-operations-1"></a><a class="docs-heading-anchor-permalink" href="#Consider-StaticArrays.jl-for-small-fixed-size-vector/matrix-operations" title="Permalink"></a></h2><p>もしあなたのアプリケーションが多くの小さな（<code>&lt; 100</code> 要素）固定サイズの配列を含む場合（つまり、サイズは実行前に知られている）、<a href="https://github.com/JuliaArrays/StaticArrays.jl">StaticArrays.jl package</a>の使用を検討するかもしれません。このパッケージは、そのような配列を表現する方法を提供し、不要なヒープ割り当てを避け、コンパイラが配列の<em>サイズ</em>に特化したコードを生成できるようにします。例えば、ベクトル操作を完全に展開（ループを排除）し、要素をCPUレジスタに格納することが可能です。</p><p>例えば、2次元の幾何学で計算を行う場合、2成分のベクトルを使った多くの計算があるかもしれません。StaticArrays.jlの<code>SVector</code>型を使用することで、ベクトル<code>v</code>と<code>w</code>に対して<code>norm(3v - w)</code>のような便利なベクトル表記や演算を使用でき、コンパイラがコードを展開して<code>@inbounds hypot(3v[1]-w[1], 3v[2]-w[2])</code>と同等の最小限の計算にすることができます。</p><h2 id="Avoid-string-interpolation-for-I/O"><a class="docs-heading-anchor" href="#Avoid-string-interpolation-for-I/O">Avoid string interpolation for I/O</a><a id="Avoid-string-interpolation-for-I/O-1"></a><a class="docs-heading-anchor-permalink" href="#Avoid-string-interpolation-for-I/O" title="Permalink"></a></h2><p>ファイル（または他のI/Oデバイス）にデータを書き込む際に、余分な中間文字列を形成することはオーバーヘッドの原因となります。次のようにする代わりに：</p><pre><code class="language-julia hljs">println(file, &quot;$a $b&quot;)</code></pre><p>使用：</p><pre><code class="language-julia hljs">println(file, a, &quot; &quot;, b)</code></pre><p>最初のバージョンのコードは文字列を形成し、それをファイルに書き込みます。一方、2番目のバージョンは値を直接ファイルに書き込みます。また、場合によっては文字列補間が読みづらくなることに注意してください。考慮してください：</p><pre><code class="language-julia hljs">println(file, &quot;$(f(a))$(f(b))&quot;)</code></pre><p>対決:</p><pre><code class="language-julia hljs">println(file, f(a), f(b))</code></pre><h2 id="Optimize-network-I/O-during-parallel-execution"><a class="docs-heading-anchor" href="#Optimize-network-I/O-during-parallel-execution">Optimize network I/O during parallel execution</a><a id="Optimize-network-I/O-during-parallel-execution-1"></a><a class="docs-heading-anchor-permalink" href="#Optimize-network-I/O-during-parallel-execution" title="Permalink"></a></h2><p>リモート関数を並行して実行する場合:</p><pre><code class="language-julia hljs">using Distributed

responses = Vector{Any}(undef, nworkers())
@sync begin
    for (idx, pid) in enumerate(workers())
        @async responses[idx] = remotecall_fetch(foo, pid, args...)
    end
end</code></pre><p>より速い:</p><pre><code class="language-julia hljs">using Distributed

refs = Vector{Any}(undef, nworkers())
for (idx, pid) in enumerate(workers())
    refs[idx] = @spawnat pid foo(args...)
end
responses = [fetch(r) for r in refs]</code></pre><p>前者はすべてのワーカーに対して1回のネットワーク往復を行いますが、後者は2回のネットワーク呼び出しを行います - 最初は <a href="../stdlib/Distributed.html#Distributed.@spawnat"><code>@spawnat</code></a> によるもので、2回目は <a href="../base/parallel.html#Base.fetch-Tuple{Task}"><code>fetch</code></a> によるものです（あるいは <a href="../base/parallel.html#Base.wait"><code>wait</code></a> でも）。<code>4d61726b646f776e2e436f64652822222c202266657463682229_40726566</code>/<code>4d61726b646f776e2e436f64652822222c2022776169742229_40726566</code> は直列で実行されており、全体的にパフォーマンスが低下しています。</p><h2 id="Fix-deprecation-warnings"><a class="docs-heading-anchor" href="#Fix-deprecation-warnings">Fix deprecation warnings</a><a id="Fix-deprecation-warnings-1"></a><a class="docs-heading-anchor-permalink" href="#Fix-deprecation-warnings" title="Permalink"></a></h2><p>非推奨の関数は、関連する警告を一度だけ表示するために内部でルックアップを実行します。この追加のルックアップは、著しい遅延を引き起こす可能性があるため、非推奨の関数のすべての使用は、警告で示された通りに修正する必要があります。</p><h2 id="Tweaks"><a class="docs-heading-anchor" href="#Tweaks">Tweaks</a><a id="Tweaks-1"></a><a class="docs-heading-anchor-permalink" href="#Tweaks" title="Permalink"></a></h2><p>これらは、タイトな内部ループで役立つかもしれないいくつかの小さなポイントです。</p><ul><li>不必要な配列を避けてください。例えば、<a href="../base/collections.html#Base.sum"><code>sum([x,y,z])</code></a>の代わりに<code>x+y+z</code>を使用してください。</li><li>Use <a href="../base/math.html#Base.abs2"><code>abs2(z)</code></a> instead of <a href="../base/math.html#Base.:^-Tuple{Number, Number}"><code>abs(z)^2</code></a> for complex <code>z</code>. In general, try to rewrite code to use <a href="../base/math.html#Base.abs2"><code>abs2</code></a> instead of <a href="../base/math.html#Base.abs"><code>abs</code></a> for complex arguments.</li><li>Use <a href="../base/math.html#Base.div"><code>div(x,y)</code></a> for truncating division of integers instead of <a href="../base/math.html#Base.trunc"><code>trunc(x/y)</code></a>, <a href="../base/math.html#Base.fld"><code>fld(x,y)</code></a> instead of <a href="../base/math.html#Base.floor"><code>floor(x/y)</code></a>, and <a href="../base/math.html#Base.cld"><code>cld(x,y)</code></a> instead of <a href="../base/math.html#Base.ceil"><code>ceil(x/y)</code></a>.</li></ul><h2 id="man-performance-annotations"><a class="docs-heading-anchor" href="#man-performance-annotations">Performance Annotations</a><a id="man-performance-annotations-1"></a><a class="docs-heading-anchor-permalink" href="#man-performance-annotations" title="Permalink"></a></h2><p>時には、特定のプログラムの特性を約束することで、より良い最適化を有効にすることができます。</p><ul><li><a href="../base/base.html#Base.@inbounds"><code>@inbounds</code></a>を使用して、式内の配列境界チェックを排除します。これを行う前に確信を持ってください。もし添字が境界外であれば、クラッシュや静かな破損が発生する可能性があります。</li><li><a href="../base/math.html#Base.FastMath.@fastmath"><code>@fastmath</code></a>を使用して、実数に対して正しいが、IEEE数に対しては違いをもたらす浮動小数点最適化を許可します。これを行う際は注意が必要です。数値結果が変わる可能性があります。これはclangの<code>-ffast-math</code>オプションに対応しています。</li><li><a href="../base/base.html#Base.SimdLoop.@simd"><code>@simd</code></a>を<code>for</code>ループの前に書いて、反復が独立しており、順序を変更できることを約束します。多くの場合、Juliaは<code>@simd</code>マクロなしで自動的にコードをベクトル化できますが、これはそのような変換が違法である場合、特に浮動小数点の再結合を許可し、依存メモリアクセスを無視する場合（<code>@simd ivdep</code>を含む）にのみ有益です。依存する反復を持つループに誤って<code>@simd</code>を注釈付けすると、予期しない結果をもたらす可能性があるため、<code>@simd</code>を主張する際には非常に注意してください。特に、いくつかの<code>AbstractArray</code>サブタイプに対する<code>setindex!</code>は、反復順序に本質的に依存していることに注意してください。<strong>この機能は実験的であり、将来のJuliaのバージョンで変更されるか、消える可能性があります。</strong></li></ul><p>1:nを使ってAbstractArrayにインデックスを付ける一般的な慣用句は、配列が非標準のインデックス付けを使用している場合、安全ではなく、境界チェックがオフになっているとセグメンテーションフォルトを引き起こす可能性があります。代わりに<code>LinearIndices(x)</code>または<code>eachindex(x)</code>を使用してください（詳細は<a href="../devdocs/offset-arrays.html#man-custom-indices">Arrays with custom indices</a>を参照）。</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p><code>@simd</code>は最も内側の<code>for</code>ループの直前に置く必要がありますが、<code>@inbounds</code>と<code>@fastmath</code>は、単一の式や、ネストされたコードブロック内に現れるすべての式に適用できます。例えば、<code>@inbounds begin</code>や<code>@inbounds for ...</code>を使用することができます。</p></div></div><p>ここに <code>@inbounds</code> と <code>@simd</code> マークアップの両方を使用した例があります（ここでは、最適化プログラムがあまり賢くなりすぎてベンチマークを妨害しないように <code>@noinline</code> を使用しています）：</p><pre><code class="language-julia hljs">@noinline function inner(x, y)
    s = zero(eltype(x))
    for i=eachindex(x)
        @inbounds s += x[i]*y[i]
    end
    return s
end

@noinline function innersimd(x, y)
    s = zero(eltype(x))
    @simd for i = eachindex(x)
        @inbounds s += x[i] * y[i]
    end
    return s
end

function timeit(n, reps)
    x = rand(Float32, n)
    y = rand(Float32, n)
    s = zero(Float64)
    time = @elapsed for j in 1:reps
        s += inner(x, y)
    end
    println(&quot;GFlop/sec        = &quot;, 2n*reps / time*1E-9)
    time = @elapsed for j in 1:reps
        s += innersimd(x, y)
    end
    println(&quot;GFlop/sec (SIMD) = &quot;, 2n*reps / time*1E-9)
end

timeit(1000, 1000)</code></pre><p>2.4GHzのIntel Core i5プロセッサを搭載したコンピュータでは、これが生成されます：</p><pre><code class="nohighlight hljs">GFlop/sec        = 1.9467069505224963
GFlop/sec (SIMD) = 17.578554163920018</code></pre><p>(<code>GFlop/sec</code>はパフォーマンスを測定し、大きな数値がより良いことを示します。)</p><p>ここに3種類のマークアップを使用した例があります。このプログラムは、まず1次元配列の有限差分を計算し、その結果のL2ノルムを評価します：</p><pre><code class="language-julia hljs">function init!(u::Vector)
    n = length(u)
    dx = 1.0 / (n-1)
    @fastmath @inbounds @simd for i in 1:n #by asserting that `u` is a `Vector` we can assume it has 1-based indexing
        u[i] = sin(2pi*dx*i)
    end
end

function deriv!(u::Vector, du)
    n = length(u)
    dx = 1.0 / (n-1)
    @fastmath @inbounds du[1] = (u[2] - u[1]) / dx
    @fastmath @inbounds @simd for i in 2:n-1
        du[i] = (u[i+1] - u[i-1]) / (2*dx)
    end
    @fastmath @inbounds du[n] = (u[n] - u[n-1]) / dx
end

function mynorm(u::Vector)
    n = length(u)
    T = eltype(u)
    s = zero(T)
    @fastmath @inbounds @simd for i in 1:n
        s += u[i]^2
    end
    @fastmath @inbounds return sqrt(s)
end

function main()
    n = 2000
    u = Vector{Float64}(undef, n)
    init!(u)
    du = similar(u)

    deriv!(u, du)
    nu = mynorm(du)

    @time for i in 1:10^6
        deriv!(u, du)
        nu = mynorm(du)
    end

    println(nu)
end

main()</code></pre><p>2.7 GHzのIntel Core i7プロセッサを搭載したコンピュータでは、これが生成されます：</p><pre><code class="nohighlight hljs">$ julia wave.jl;
  1.207814709 seconds
4.443986180758249

$ julia --math-mode=ieee wave.jl;
  4.487083643 seconds
4.443986180758249</code></pre><p>ここでは、オプション <code>--math-mode=ieee</code> が <code>@fastmath</code> マクロを無効にするため、結果を比較できるようになります。</p><p>この場合、<code>@fastmath</code>によるスピードアップは約3.7倍です。これは異常に大きい値であり、一般的にはスピードアップはより小さくなります。（この特定の例では、ベンチマークの作業セットがプロセッサのL1キャッシュに収まるほど小さいため、メモリアクセスのレイテンシは影響を与えず、計算時間はCPUの使用に支配されます。多くの実世界のプログラムでは、これは当てはまりません。）また、この場合、この最適化は結果を変更しませんが、一般的には結果はわずかに異なるでしょう。特に数値的に不安定なアルゴリズムの場合、結果は非常に異なることがあります。</p><p>アノテーション <code>@fastmath</code> は浮動小数点表現を再配置します。例えば、評価の順序を変更したり、特定の特別なケース（inf、nan）が発生しないと仮定したりします。この場合（およびこの特定のコンピュータ上では）、主な違いは、関数 <code>deriv</code> 内の式 <code>1 / (2*dx)</code> がループの外に持ち上げられることです（つまり、ループの外で計算されます）。これは、<code>idx = 1 / (2*dx)</code> と書いたかのようです。ループ内では、式 <code>... / (2*dx)</code> は <code>... * idx</code> となり、評価がはるかに速くなります。もちろん、コンパイラによって適用される実際の最適化と、結果として得られるスピードアップは、ハードウェアに非常に依存します。生成されたコードの変更を調べるには、Juliaの <a href="../stdlib/InteractiveUtils.html#InteractiveUtils.code_native"><code>code_native</code></a> 関数を使用できます。</p><p><code>@fastmath</code>は、計算中に<code>NaN</code>が発生しないことも前提としているため、驚くべき動作を引き起こす可能性があります。</p><pre><code class="language-julia-repl hljs">julia&gt; f(x) = isnan(x);

julia&gt; f(NaN)
true

julia&gt; f_fast(x) = @fastmath isnan(x);

julia&gt; f_fast(NaN)
false</code></pre><h2 id="Treat-Subnormal-Numbers-as-Zeros"><a class="docs-heading-anchor" href="#Treat-Subnormal-Numbers-as-Zeros">Treat Subnormal Numbers as Zeros</a><a id="Treat-Subnormal-Numbers-as-Zeros-1"></a><a class="docs-heading-anchor-permalink" href="#Treat-Subnormal-Numbers-as-Zeros" title="Permalink"></a></h2><p>サブノーマル数（以前は <a href="https://en.wikipedia.org/wiki/Denormal_number">denormal numbers</a> と呼ばれていました）は、多くの文脈で有用ですが、一部のハードウェアではパフォーマンスのペナルティが発生します。呼び出し <a href="../base/numbers.html#Base.Rounding.set_zero_subnormals"><code>set_zero_subnormals(true)</code></a> は、浮動小数点演算がサブノーマルな入力または出力をゼロとして扱うことを許可し、これにより一部のハードウェアでのパフォーマンスが向上する可能性があります。呼び出し <a href="../base/numbers.html#Base.Rounding.set_zero_subnormals"><code>set_zero_subnormals(false)</code></a> は、サブノーマル数に対して厳密なIEEEの動作を強制します。</p><p>以下は、サブノーマルが一部のハードウェアでパフォーマンスに顕著な影響を与える例です：</p><pre><code class="language-julia hljs">function timestep(b::Vector{T}, a::Vector{T}, Δt::T) where T
    @assert length(a)==length(b)
    n = length(b)
    b[1] = 1                            # Boundary condition
    for i=2:n-1
        b[i] = a[i] + (a[i-1] - T(2)*a[i] + a[i+1]) * Δt
    end
    b[n] = 0                            # Boundary condition
end

function heatflow(a::Vector{T}, nstep::Integer) where T
    b = similar(a)
    for t=1:div(nstep,2)                # Assume nstep is even
        timestep(b,a,T(0.1))
        timestep(a,b,T(0.1))
    end
end

heatflow(zeros(Float32,10),2)           # Force compilation
for trial=1:6
    a = zeros(Float32,1000)
    set_zero_subnormals(iseven(trial))  # Odd trials use strict IEEE arithmetic
    @time heatflow(a,1000)
end</code></pre><p>これは次のような出力を生成します。</p><pre><code class="nohighlight hljs">  0.002202 seconds (1 allocation: 4.063 KiB)
  0.001502 seconds (1 allocation: 4.063 KiB)
  0.002139 seconds (1 allocation: 4.063 KiB)
  0.001454 seconds (1 allocation: 4.063 KiB)
  0.002115 seconds (1 allocation: 4.063 KiB)
  0.001455 seconds (1 allocation: 4.063 KiB)</code></pre><p>各偶数イテレーションが著しく速いことに注意してください。</p><p>この例は、多くの非正規数を生成します。なぜなら、<code>a</code> の値が指数的に減少する曲線になり、時間が経つにつれて徐々に平坦になっていくからです。</p><p>サブノーマルをゼロとして扱うことは注意が必要です。なぜなら、そうすることでいくつかの恒等式が破壊されるからです。例えば、<code>x-y == 0</code> は <code>x == y</code> を意味します。</p><pre><code class="language-julia-repl hljs">julia&gt; x = 3f-38; y = 2f-38;

julia&gt; set_zero_subnormals(true); (x - y, x == y)
(0.0f0, false)

julia&gt; set_zero_subnormals(false); (x - y, x == y)
(1.0000001f-38, false)</code></pre><p>いくつかのアプリケーションでは、サブノーマル数をゼロにする代わりに、わずかなノイズを注入する方法があります。たとえば、<code>a</code>をゼロで初期化するのではなく、次のように初期化します：</p><pre><code class="language-julia hljs">a = rand(Float32,1000) * 1.f-9</code></pre><h2 id="man-code-warntype"><a class="docs-heading-anchor" href="#man-code-warntype"><a href="../stdlib/InteractiveUtils.html#InteractiveUtils.@code_warntype"><code>@code_warntype</code></a></a><a id="man-code-warntype-1"></a><a class="docs-heading-anchor-permalink" href="#man-code-warntype" title="Permalink"></a></h2><p>マクロ <a href="../stdlib/InteractiveUtils.html#InteractiveUtils.@code_warntype"><code>@code_warntype</code></a> （またはその関数バリアント <a href="../stdlib/InteractiveUtils.html#InteractiveUtils.code_warntype"><code>code_warntype</code></a>）は、型に関連する問題を診断するのに役立つことがあります。以下はその例です：</p><pre><code class="language-julia-repl hljs">julia&gt; @noinline pos(x) = x &lt; 0 ? 0 : x;

julia&gt; function f(x)
           y = pos(x)
           return sin(y*x + 1)
       end;

julia&gt; @code_warntype f(3.2)
MethodInstance for f(::Float64)
  from f(x) @ Main REPL[9]:1
Arguments
  #self#::Core.Const(f)
  x::Float64
Locals
  y::Union{Float64, Int64}
Body::Float64
1 ─      (y = Main.pos(x))
│   %2 = (y * x)::Float64
│   %3 = (%2 + 1)::Float64
│   %4 = Main.sin(%3)::Float64
└──      return %4</code></pre><p>Interpreting the output of <a href="../stdlib/InteractiveUtils.html#InteractiveUtils.@code_warntype"><code>@code_warntype</code></a>, like that of its cousins <a href="../stdlib/InteractiveUtils.html#InteractiveUtils.@code_lowered"><code>@code_lowered</code></a>, <a href="../stdlib/InteractiveUtils.html#InteractiveUtils.@code_typed"><code>@code_typed</code></a>, <a href="../stdlib/InteractiveUtils.html#InteractiveUtils.@code_llvm"><code>@code_llvm</code></a>, and <a href="../stdlib/InteractiveUtils.html#InteractiveUtils.@code_native"><code>@code_native</code></a>, takes a little practice. Your code is being presented in form that has been heavily digested on its way to generating compiled machine code. Most of the expressions are annotated by a type, indicated by the <code>::T</code> (where <code>T</code> might be <a href="../base/numbers.html#Core.Float64"><code>Float64</code></a>, for example). The most important characteristic of <a href="../stdlib/InteractiveUtils.html#InteractiveUtils.@code_warntype"><code>@code_warntype</code></a> is that non-concrete types are displayed in red; since this document is written in Markdown, which has no color, in this document, red text is denoted by uppercase.</p><p>関数の推測された戻り値の型は <code>Body::Float64</code> として表示されています。次の行は、JuliaのSSA IR形式での <code>f</code> の本体を表しています。番号付きのボックスはラベルであり、コード内のジャンプ（<code>goto</code>を介して）のターゲットを表しています。本体を見てみると、最初に <code>pos</code> が呼び出され、その戻り値は大文字で示された <code>Union</code> 型 <code>Union{Float64, Int64}</code> として推測されています。これは、具体的な型ではないため、入力型に基づいて <code>pos</code> の正確な戻り値の型を知ることができないことを意味します。しかし、<code>y*x</code> の結果は、<code>y</code> が <code>Float64</code> であろうと <code>Int64</code> であろうと <code>Float64</code> になります。最終的な結果として、<code>f(x::Float64)</code> は出力において型不安定ではなく、いくつかの中間計算が型不安定であっても問題ありません。</p><p>この情報をどのように使用するかはあなた次第です。明らかに、<code>pos</code>を型安定に固定するのが最も良いでしょう。そうすれば、<code>f</code>内のすべての変数が具体的になり、そのパフォーマンスは最適になります。しかし、この種の<em>一時的な</em>型不安定性がそれほど重要でない場合もあります。たとえば、<code>pos</code>が単独で使用されない場合、<code>f</code>の出力が型安定であること（<a href="../base/numbers.html#Core.Float64"><code>Float64</code></a>入力に対して）は、後のコードが型不安定性の影響を受けるのを防ぎます。これは、型不安定性を修正するのが難しいまたは不可能な場合に特に関連します。そのような場合、上記のヒント（たとえば、型注釈を追加することや関数を分割すること）は、型不安定性からの「損害」を抑えるための最良のツールです。また、Julia Baseにも型不安定な関数があることに注意してください。たとえば、関数<a href="../base/arrays.html#Base.findfirst-Tuple{Any}"><code>findfirst</code></a>は、キーが見つかった配列のインデックスを返し、見つからなかった場合は<code>nothing</code>を返します。これは明確な型不安定性です。重要である可能性のある型不安定性を見つけやすくするために、<code>missing</code>または<code>nothing</code>を含む<code>Union</code>は赤ではなく黄色で色分けされています。</p><p>以下の例は、非葉タイプを含むとマークされた式を解釈するのに役立つかもしれません：</p><ul><li><p><code>Body::Union{T1,T2})</code> で始まる関数本体</p><ul><li>解釈: 不安定な戻り値の型を持つ関数</li><li>提案: 戻り値の型を安定させるために、注釈を付ける必要があってもそうしてください。</li></ul></li><li><p><code>invoke Main.g(%%x::Int64)::Union{Float64, Int64}</code></p><ul><li>解釈: 型が不安定な関数 <code>g</code> への呼び出し。</li><li>提案: 関数を修正するか、必要に応じて戻り値に注釈を付けてください。</li></ul></li><li><p><code>invoke Base.getindex(%%x::Array{Any,1}, 1::Int64)::Any</code></p><ul><li>解釈: 型が不適切な配列の要素にアクセスすること</li><li>提案: より明確に定義された型の配列を使用するか、必要に応じて個々の要素アクセスの型を注釈してください。</li></ul></li><li><p><code>Base.getfield(%%x, :(:data))::Array{Float64,N} where N</code></p><ul><li>解釈：リーフ型でないタイプのフィールドを取得すること。ここで、<code>x</code>のタイプ、例えば<code>ArrayContainer</code>は、フィールド<code>data::Array{T}</code>を持っていました。しかし、<code>Array</code>は具体的なタイプであるために次元<code>N</code>も必要です。</li><li>提案: <code>Array{T,3}</code>や<code>Array{T,N}</code>のような具体的な型を使用してください。ここで、<code>N</code>は現在<code>ArrayContainer</code>のパラメータです。</li></ul></li></ul><h2 id="man-performance-captured"><a class="docs-heading-anchor" href="#man-performance-captured">Performance of captured variable</a><a id="man-performance-captured-1"></a><a class="docs-heading-anchor-permalink" href="#man-performance-captured" title="Permalink"></a></h2><p>次の例を考えて、内部関数を定義します：</p><pre><code class="language-julia hljs">function abmult(r::Int)
    if r &lt; 0
        r = -r
    end
    f = x -&gt; x * r
    return f
end</code></pre><p>関数 <code>abmult</code> は、引数を <code>r</code> の絶対値で乗算する関数 <code>f</code> を返します。<code>f</code> に割り当てられた内部関数は「クロージャ」と呼ばれます。内部関数は、言語によって <code>do</code> ブロックやジェネレーター式にも使用されます。</p><p>このスタイルのコードは、言語に対してパフォーマンスの課題を提示します。パーサーは、これを低レベルの命令に翻訳する際に、内部関数を別のコードブロックに抽出することによって、上記のコードを大幅に再編成します。内部関数とその囲むスコープで共有される「キャプチャされた」変数（例えば <code>r</code>）も、内部関数と外部関数の両方からアクセス可能なヒープに割り当てられた「ボックス」に抽出されます。これは、言語が内部スコープの <code>r</code> が外部スコープの <code>r</code> と同一でなければならないと規定しているためであり、外部スコープ（または別の内部関数）が <code>r</code> を変更した後でも同様です。</p><p>前の段落での議論は「パーサー」に言及しており、これは <code>abmult</code> を含むモジュールが最初にロードされる際に行われるコンパイルのフェーズを指します。これは、最初に呼び出される後のフェーズとは対照的です。パーサーは <code>Int</code> が固定型であることや、<code>r = -r</code> という文が <code>Int</code> を別の <code>Int</code> に変換することを「知っている」わけではありません。型推論の魔法はコンパイルの後のフェーズで行われます。</p><p>したがって、パーサーは <code>r</code> が固定の型（<code>Int</code>）を持っていることや、内部関数が作成された後に <code>r</code> の値が変わらないこと（そのためボックスが不要であること）を知りません。したがって、パーサーは <code>Any</code> のような抽象型を持つオブジェクトを保持するボックスのコードを生成します。これにより、<code>r</code> の各出現に対して実行時型ディスパッチが必要になります。これは、上記の関数に <code>@code_warntype</code> を適用することで確認できます。ボクシングと実行時型ディスパッチの両方がパフォーマンスの低下を引き起こす可能性があります。</p><p>もしキャプチャされた変数がパフォーマンスに重要なコードセクションで使用される場合、以下のヒントがその使用をパフォーマンス向上に役立ちます。まず、キャプチャされた変数がその型を変更しないことが分かっている場合、これは型注釈を使って明示的に宣言できます（変数に対して、右辺ではなく）：</p><pre><code class="language-julia hljs">function abmult2(r0::Int)
    r::Int = r0
    if r &lt; 0
        r = -r
    end
    f = x -&gt; x * r
    return f
end</code></pre><p>型注釈は、パーサーがボックス内のオブジェクトに具体的な型を関連付けることができるため、キャプチャによって失われたパフォーマンスを部分的に回復します。さらに、キャプチャされた変数が（クロージャが作成された後に再代入されないため）全くボックス化される必要がない場合、次のように <code>let</code> ブロックで示すことができます。</p><pre><code class="language-julia hljs">function abmult3(r::Int)
    if r &lt; 0
        r = -r
    end
    f = let r = r
            x -&gt; x * r
    end
    return f
end</code></pre><p><code>let</code> ブロックは、新しい変数 <code>r</code> を作成し、そのスコープは内部関数のみに限定されます。2 番目の技術は、キャプチャされた変数が存在する場合でも、完全な言語パフォーマンスを回復します。これはコンパイラの急速に進化している側面であり、将来のリリースではパフォーマンスを達成するためにこの程度のプログラマーの注釈が必要なくなる可能性が高いことに注意してください。その間、<a href="https://github.com/c42f/FastClosures.jl">FastClosures</a> のようなユーザー提供のパッケージが、<code>abmult3</code> のように <code>let</code> ステートメントの挿入を自動化します。</p><h2 id="man-multithreading-linear-algebra"><a class="docs-heading-anchor" href="#man-multithreading-linear-algebra">Multithreading and linear algebra</a><a id="man-multithreading-linear-algebra-1"></a><a class="docs-heading-anchor-permalink" href="#man-multithreading-linear-algebra" title="Permalink"></a></h2><p>このセクションは、各スレッドで線形代数演算を行うマルチスレッドのJuliaコードに適用されます。実際、これらの線形代数演算はBLAS / LAPACK呼び出しを含み、これら自体もマルチスレッドです。この場合、2つの異なるタイプのマルチスレッドによってコアが過剰に割り当てられないようにする必要があります。</p><p>Juliaは線形代数のために独自のOpenBLASのコピーをコンパイルして使用しており、そのスレッド数は環境変数<code>OPENBLAS_NUM_THREADS</code>によって制御されます。これは、Juliaを起動する際のコマンドラインオプションとして設定することも、Juliaセッション中に<code>BLAS.set_num_threads(N)</code>を使用して変更することもできます（サブモジュール<code>BLAS</code>は<code>using LinearAlgebra</code>によってエクスポートされます）。現在の値は<code>BLAS.get_num_threads()</code>で取得できます。</p><p>ユーザーが何も指定しない場合、JuliaはOpenBLASスレッドの数に対して合理的な値を選ぼうとします（例：プラットフォーム、Juliaのバージョンなどに基づいて）。ただし、一般的には値を手動で確認し設定することが推奨されます。OpenBLASの動作は以下の通りです：</p><ul><li><code>OPENBLAS_NUM_THREADS=1</code> の場合、OpenBLASは呼び出し元のJuliaスレッドを使用します。つまり、計算を実行するJuliaスレッドの中で「存在する」ことになります。</li><li><code>OPENBLAS_NUM_THREADS=N&gt;1</code> の場合、OpenBLAS は独自のスレッドプールを作成し、管理します（合計で <code>N</code>）。すべての Julia スレッドで共有されるのは、1 つの OpenBLAS スレッドプールだけです。</li></ul><p>Juliaをマルチスレッドモードで<code>JULIA_NUM_THREADS=X</code>で起動するときは、一般的に<code>OPENBLAS_NUM_THREADS=1</code>に設定することが推奨されます。上記の動作を考慮すると、BLASスレッドの数を<code>N&gt;1</code>に増やすと、特に<code>N&lt;&lt;X</code>の場合、パフォーマンスが悪化する可能性が非常に高いです。しかし、これはあくまで経験則であり、各スレッド数を設定する最良の方法は、特定のアプリケーションで実験することです。</p><h2 id="man-backends-linear-algebra"><a class="docs-heading-anchor" href="#man-backends-linear-algebra">Alternative linear algebra backends</a><a id="man-backends-linear-algebra-1"></a><a class="docs-heading-anchor-permalink" href="#man-backends-linear-algebra" title="Permalink"></a></h2><p>OpenBLASの代替として、線形代数のパフォーマンスを向上させるための他のバックエンドがいくつか存在します。代表的な例としては <a href="https://github.com/JuliaLinearAlgebra/MKL.jl">MKL.jl</a> と <a href="https://github.com/JuliaMath/AppleAccelerate.jl">AppleAccelerate.jl</a> があります。</p><p>これらは外部パッケージであるため、ここでは詳細については議論しません。それぞれのドキュメントを参照してください（特に、マルチスレッドに関してOpenBLASとは異なる動作をするためです）。</p><h2 id="Execution-latency,-package-loading-and-package-precompiling-time"><a class="docs-heading-anchor" href="#Execution-latency,-package-loading-and-package-precompiling-time">Execution latency, package loading and package precompiling time</a><a id="Execution-latency,-package-loading-and-package-precompiling-time-1"></a><a class="docs-heading-anchor-permalink" href="#Execution-latency,-package-loading-and-package-precompiling-time" title="Permalink"></a></h2><h3 id="Reducing-time-to-first-plot-etc."><a class="docs-heading-anchor" href="#Reducing-time-to-first-plot-etc.">Reducing time to first plot etc.</a><a id="Reducing-time-to-first-plot-etc.-1"></a><a class="docs-heading-anchor-permalink" href="#Reducing-time-to-first-plot-etc." title="Permalink"></a></h3><p>最初にjuliaメソッドが呼び出されると、それ（およびそれが呼び出すメソッド、または静的に決定できるメソッド）はコンパイルされます。<a href="profile.html#@time"><code>@time</code></a>マクロファミリーはこれを示しています。</p><pre><code class="nohighlight hljs">julia&gt; foo() = rand(2,2) * rand(2,2)
foo (generic function with 1 method)

julia&gt; @time @eval foo();
  0.252395 seconds (1.12 M allocations: 56.178 MiB, 2.93% gc time, 98.12% compilation time)

julia&gt; @time @eval foo();
  0.000156 seconds (63 allocations: 2.453 KiB)</code></pre><p><code>@time @eval</code>はコンパイル時間を測定するのに優れていることに注意してください。なぜなら、<a href="../base/base.html#Base.@eval"><code>@eval</code></a>なしでは、タイミングが始まる前にコンパイルがすでに行われている可能性があるからです。</p><p>パッケージを開発する際、<em>プリコンパイル</em>を使用することで、ユーザーの体験を向上させることができるかもしれません。これにより、パッケージを使用する際に、ユーザーが使用するコードはすでにコンパイルされています。パッケージコードを効果的にプリコンパイルするためには、<a href="https://julialang.github.io/PrecompileTools.jl/stable/"><code>PrecompileTools.jl</code></a>を使用して、プリコンパイル時に典型的なパッケージ使用を代表する「プリコンパイルワークロード」を実行することをお勧めします。これにより、ネイティブコンパイルされたコードがパッケージの<code>pkgimage</code>キャッシュにキャッシュされ、こうした使用に対する「初回実行までの時間」（TTFXと呼ばれることが多い）を大幅に短縮します。</p><p><a href="https://julialang.github.io/PrecompileTools.jl/stable/"><code>PrecompileTools.jl</code></a> ワークロードは無効にすることができ、場合によってはプリコンパイルに余分な時間をかけたくない場合に、Preferencesを介して構成することもできます。これは、パッケージの開発中に該当することがあります。</p><h3 id="Reducing-package-loading-time"><a class="docs-heading-anchor" href="#Reducing-package-loading-time">Reducing package loading time</a><a id="Reducing-package-loading-time-1"></a><a class="docs-heading-anchor-permalink" href="#Reducing-package-loading-time" title="Permalink"></a></h3><p>パッケージの読み込みにかかる時間を短く保つことは通常有益です。パッケージ開発者にとっての一般的な良い実践には以下が含まれます：</p><ol><li>依存関係は本当に必要なものだけに減らしましょう。他のパッケージとの相互運用性をサポートするために、<a href="../base/math.html#Base.:--Tuple{Any, Any}">package extensions</a>の使用を検討してください。これにより、基本的な依存関係が膨らむことを避けられます。</li><li><a href="../base/base.html#__init__"><code>__init__()</code></a> 関数の使用は、代替手段がない場合を除き避けてください。特に、多くのコンパイルを引き起こす可能性があるものや、実行に時間がかかるものは避けるべきです。</li><li>可能な場合は、依存関係およびパッケージコードから <a href="https://julialang.org/blog/2020/08/invalidations/">invalidations</a> を修正してください。</li></ol><p>ツール <a href="../stdlib/InteractiveUtils.html#Base.@time_imports"><code>@time_imports</code></a> は、REPL で上記の要因を確認するのに役立ちます。</p><pre><code class="language-julia-repl hljs">julia&gt; @time @time_imports using Plots
      0.5 ms  Printf
     16.4 ms  Dates
      0.7 ms  Statistics
               ┌ 23.8 ms SuiteSparse_jll.__init__() 86.11% compilation time (100% recompilation)
     90.1 ms  SuiteSparse_jll 91.57% compilation time (82% recompilation)
      0.9 ms  Serialization
               ┌ 39.8 ms SparseArrays.CHOLMOD.__init__() 99.47% compilation time (100% recompilation)
    166.9 ms  SparseArrays 23.74% compilation time (100% recompilation)
      0.4 ms  Statistics → SparseArraysExt
      0.5 ms  TOML
      8.0 ms  Preferences
      0.3 ms  PrecompileTools
      0.2 ms  Reexport
... many deps omitted for example ...
      1.4 ms  Tar
               ┌ 73.8 ms p7zip_jll.__init__() 99.93% compilation time (100% recompilation)
     79.4 ms  p7zip_jll 92.91% compilation time (100% recompilation)
               ┌ 27.7 ms GR.GRPreferences.__init__() 99.77% compilation time (100% recompilation)
     43.0 ms  GR 64.26% compilation time (100% recompilation)
               ┌ 2.1 ms Plots.__init__() 91.80% compilation time (100% recompilation)
    300.9 ms  Plots 0.65% compilation time (100% recompilation)
  1.795602 seconds (3.33 M allocations: 190.153 MiB, 7.91% gc time, 39.45% compilation time: 97% of which was recompilation)
</code></pre><p>この例では、複数のパッケージが読み込まれていることに注意してください。いくつかは <code>__init__()</code> 関数を持ち、その中にはコンパイルを引き起こすものや再コンパイルを引き起こすものがあります。再コンパイルは、以前のパッケージがメソッドを無効にすることによって引き起こされます。そして、このような場合、次のパッケージが <code>__init__()</code> 関数を実行するときに、コードが実行される前に再コンパイルが発生することがあります。</p><p>さらに、<code>SparseArrays</code>が依存関係ツリーにあるため、<code>Statistics</code>拡張機能<code>SparseArraysExt</code>が有効になっていることに注意してください。すなわち、<code>0.4 ms  Statistics → SparseArraysExt</code>を参照してください。</p><p>このレポートは、依存関係のロード時間のコストがそれがもたらす機能に見合うものかどうかを見直す良い機会を提供します。また、<code>Pkg</code>ユーティリティの<code>why</code>を使用して、間接依存関係が存在する理由を報告することもできます。</p><pre><code class="nohighlight hljs">(CustomPackage) pkg&gt; why FFMPEG_jll
  Plots → FFMPEG → FFMPEG_jll
  Plots → GR → GR_jll → FFMPEG_jll</code></pre><p>また、パッケージがもたらす間接的な依存関係を確認するには、<code>pkg&gt; rm</code> コマンドでパッケージを削除し、マニフェストから削除された依存関係を確認した後、<code>pkg&gt; undo</code> コマンドで変更を元に戻すことができます。</p><p>もしロード時間が遅い <code>__init__()</code> メソッドによるコンパイルに支配されている場合、何がコンパイルされているかを特定するための冗長な方法は、julia 引数 <code>--trace-compile=stderr</code> を使用することです。これにより、メソッドがコンパイルされるたびに <a href="../base/base.html#Base.precompile"><code>precompile</code></a> ステートメントが報告されます。たとえば、完全なセットアップは次のようになります：</p><pre><code class="nohighlight hljs">$ julia --startup-file=no --trace-compile=stderr
julia&gt; @time @time_imports using CustomPackage
...</code></pre><p><code>--startup-file=no</code>は、<code>startup.jl</code>にあるパッケージからテストを隔離するのに役立ちます。</p><p>再コンパイルの理由に関するさらなる分析は、<a href="https://github.com/timholy/SnoopCompile.jl"><code>SnoopCompile</code></a> パッケージを使用することで達成できます。</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="stacktraces.html">« Stack Traces</a><a class="docs-footer-nextpage" href="workflow-tips.html">Workflow Tips »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Tuesday 27 May 2025 09:20">Tuesday 27 May 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
