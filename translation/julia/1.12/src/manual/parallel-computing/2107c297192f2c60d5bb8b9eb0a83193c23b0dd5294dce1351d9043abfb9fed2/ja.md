# Parallel Computing

Juliaは、次の4つのカテゴリの同時および並列プログラミングをサポートしています：

1. **非同期の「タスク」、またはコルーチン**:

    Julia タスクは、I/O、イベント処理、プロデューサー-コンシューマー プロセス、および同様のパターンの計算を一時停止および再開することを可能にします。 タスクは、[`wait`](@ref) や [`fetch`](@ref) のような操作を通じて同期し、[`Channel`](@ref) を介して通信します。 厳密には自ら並列計算ではありませんが、Julia は複数のスレッドで [`Task`](@ref) をスケジュールすることを許可します。
2. **マルチスレッド**:

    Juliaの [multi-threading](@ref man-multithreading) は、複数のスレッドまたはCPUコアでタスクを同時にスケジュールする能力を提供し、メモリを共有します。これは通常、自分のPCや単一の大規模マルチコアサーバーで並列処理を得る最も簡単な方法です。Juliaのマルチスレッドは構成可能です。あるマルチスレッド関数が別のマルチスレッド関数を呼び出すと、Juliaは利用可能なリソースに対してすべてのスレッドをグローバルにスケジュールし、オーバーサブスクリプションを避けます。
3. **分散コンピューティング**:

    分散コンピューティングは、別々のメモリ空間を持つ複数のJuliaプロセスを実行します。これらは同じコンピュータ上でも、複数のコンピュータ上でも実行できます。[`Distributed`](@ref man-distributed)標準ライブラリは、Julia関数のリモート実行の機能を提供します。この基本的なビルディングブロックを使用することで、さまざまな種類の分散コンピューティング抽象を構築することが可能です。[`DistributedArrays.jl`](https://github.com/JuliaParallel/DistributedArrays.jl)のようなパッケージは、そのような抽象の一例です。一方、[`MPI.jl`](https://github.com/JuliaParallel/MPI.jl)や[`Elemental.jl`](https://github.com/JuliaParallel/Elemental.jl)のようなパッケージは、既存のMPIエコシステムのライブラリへのアクセスを提供します。
4. **GPUコンピューティング**:

    Julia GPUコンパイラは、GPU上でネイティブにJuliaコードを実行する機能を提供します。GPUをターゲットにしたJuliaパッケージの豊富なエコシステムがあります。[JuliaGPU.org](https://juliagpu.org)ウェブサイトでは、機能、サポートされているGPU、関連パッケージ、およびドキュメントのリストが提供されています。
